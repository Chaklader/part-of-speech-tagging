# C-2: Probability Theory and Bayesian Methods

1. Fundamentals of Probability

    - Law of Conditional Probability
    - Law of Total Probability
    - Chain Rule of Probability
    - Bayes' Theorem and Its Applications
    - Independence and Conditional Independence

2. Working with Probability Distributions
    - Discrete Probability Distributions
    - Joint and Marginal Probabilities
    - Calculating Conditional Probabilities
    - Normalization Methods
    - Complex Probability Examples

#### Fundamentals of Probability

##### Law of Conditional Probability

Conditional probability is the foundation of Bayesian reasoning. It answers the question: "Given that event B has
occurred, what is the probability that event A will occur?" This is written as P(A|B).

The formal definition of conditional probability is:

$$P(A|B) = \frac{P(A \cap B)}{P(B)}$$

Where:

- P(A|B) is the probability of event A given that event B has occurred
- P(A ∩ B) is the probability of both events A and B occurring (joint probability)
- P(B) is the probability of event B occurring (and must be greater than zero)

This can be rearranged to give us the multiplication rule:

$$P(A \cap B) = P(A|B) \times P(B)$$

This form tells us how to calculate the joint probability of two events.

For example, if we know the probability of rain tomorrow is 0.3, and the probability of heavy traffic given that it
rains is 0.8, then the probability of both rain and heavy traffic tomorrow is:

$$P(\text{Rain} \cap \text{Traffic}) = P(\text{Traffic}|\text{Rain}) \times P(\text{Rain}) = 0.8 \times 0.3 = 0.24$$

Conditional probability has several important properties:

1. **Range constraint**: $0 \leq P(A|B) \leq 1$
    - Like all probabilities, conditional probabilities must be between 0 and 1
2. **Nonzero denominator**: $P(B)$ must be greater than 0
    - We can only condition on events that have a nonzero probability of occurring
3. **Asymmetry**: $P(A|B) \neq P(B|A)$ in general
    - The probability of A given B is typically different from the probability of B given A
    - This asymmetry is what makes Bayes' theorem so useful
4. **Independence**: When A and B are independent events, $P(A \cap B) = P(A)P(B)$ and $P(A|B) = P(A)$
    - If A and B are independent, knowing B occurred doesn't change the probability of A occurring

Conditional probability is often illustrated using tree diagrams or tables to visualize the branching possibilities:

```mermaid
graph TD
    A["Event Space"] --> B["B occurs: P(B)"]
    A --> C["B doesn't occur: P(¬B)"]
    B --> D["A occurs given B: P(A|B)"]
    B --> E["A doesn't occur given B: P(¬A|B)"]
    C --> F["A occurs given ¬B: P(A|¬B)"]
    C --> G["A doesn't occur given ¬B: P(¬A|¬B)"]
```

We can extend conditional probability to three or more events by applying the same principle repeatedly:

For three events A, B, and C:

$$P(A|B,C) = \frac{P(A \cap B \cap C)}{P(B \cap C)}$$

This can be rearranged to:

$$P(A \cap B \cap C) = P(A|B,C) \times P(B \cap C)$$

Understanding conditional probability is essential for reasoning about uncertain events and forms the foundation for
more advanced concepts like Bayes' theorem and probabilistic graphical models.

##### Law of Conditional Probability

The law of conditional probability is a fundamental concept that helps us calculate the probability of one event
occurring when we know another event has already occurred.

###### Core Definition

Conditional probability is defined by the formula:

**P(A|B) = P(A ∩ B) / P(B)**

Where:

- **P(A|B)** means "the probability of A given B"
- **P(A ∩ B)** means "the probability of both A and B occurring"
- **P(B)** means "the probability of B occurring"

This formula only works when P(B) > 0, since we can't condition on an impossible event.

###### Intuitive Understanding

Think of conditional probability as focusing on a smaller universe where B has already happened. Within this reduced
space, we ask what portion also includes event A.

For example, if we know a student was accepted to a selective program (event B), how does that change our estimate of
whether they have high test scores (event A)?

###### The Multiplication Rule

We can rearrange the conditional probability formula to get:

**P(A ∩ B) = P(A|B) × P(B)**

This multiplication rule lets us find the probability of two events happening together by first finding the probability
of one event, then multiplying by the conditional probability of the second given the first.

```mermaid
graph LR
    A["P(B)"] --> C["P(A∩B)"]
    B["P(A|B)"] --> C
    C --> D["P(A∩B) = P(A|B) × P(B)"]
```

###### Key Properties

1. Like all probabilities, P(A|B) ranges from 0 to 1
2. Generally, P(A|B) is not equal to P(B|A)
3. P(B) must be greater than zero
4. For any fixed event B, the sum of conditional probabilities P(X|B) across all possible outcomes X equals 1

###### Independence

Events A and B are independent if knowing B occurred doesn't change the probability of A. Mathematically:

**If A and B are independent, then P(A|B) = P(A)**

When independence holds, we can simplify to: **P(A ∩ B) = P(A) × P(B)**

This provides a powerful simplification in many probability problems.

###### Chain Rule for Multiple Events

For three events, we can extend our approach:

**P(A,B,C) = P(A|B,C) × P(B|C) × P(C)**

This results from applying the multiplication rule twice:

1. First, P(A,B,C) = P(A|B,C) × P(B,C)
2. Then, substituting P(B,C) = P(B|C) × P(C)

```mermaid
flowchart TD
    A["P(A,B,C)"] --> B["P(A|B,C) × P(B,C)"]
    B --> C["P(A|B,C) × P(B|C) × P(C)"]
```

This chain rule forms the mathematical foundation for Bayesian networks and other probabilistic graphical models by
allowing us to break down complex joint probabilities into simpler conditional components.

###### Example Application

Consider a medical test scenario:

- 1% of the population has a certain disease (P(D) = 0.01)
- The test is 95% accurate for detecting the disease (P(T|D) = 0.95)
- The false positive rate is 10% (P(T|not D) = 0.10)

If someone tests positive, what's the probability they actually have the disease?

We need P(D|T), which we can find using conditional probability: P(D|T) = P(T|D) × P(D) / P(T)

Where P(T) = P(T|D) × P(D) + P(T|not D) × P(not D) = 0.95 × 0.01 + 0.10 × 0.99 = 0.0095 + 0.099 = 0.1085

Therefore: P(D|T) = 0.95 × 0.01 / 0.1085 ≈ 0.088 or about 8.8%

This example illustrates how conditional probability helps us update our beliefs based on new evidence—a concept at the
heart of Bayesian reasoning.

The law of conditional probability is a fundamental concept that helps us calculate the probability of one event
occurring when we know another event has already occurred.

###### Core Definition

Conditional probability is defined by the formula:

**P(A|B) = P(A ∩ B) / P(B)**

Where:

- **P(A|B)** means "the probability of A given B"
- **P(A ∩ B)** means "the probability of both A and B occurring"
- **P(B)** means "the probability of B occurring"

This formula only works when P(B) > 0, since we can't condition on an impossible event.

###### Intuitive Understanding

Think of conditional probability as focusing on a smaller universe where B has already happened. Within this reduced
space, we ask what portion also includes event A.

For example, if we know a student was accepted to a selective program (event B), how does that change our estimate of
whether they have high test scores (event A)?

###### The Multiplication Rule

We can rearrange the conditional probability formula to get:

**P(A ∩ B) = P(A|B) × P(B)**

This multiplication rule lets us find the probability of two events happening together by first finding the probability
of one event, then multiplying by the conditional probability of the second given the first.

```mermaid
graph LR
    A["P(B)"] --> C["P(A∩B)"]
    B["P(A|B)"] --> C
    C --> D["P(A∩B) = P(A|B) × P(B)"]
    style A fill:#ff9900,stroke:#333,stroke-width:2px
    style B fill:#3399ff,stroke:#333,stroke-width:2px
    style C fill:#ff66cc,stroke:#333,stroke-width:2px
    style D fill:#66cc66,stroke:#333,stroke-width:2px
```

###### Key Properties

1. Like all probabilities, P(A|B) ranges from 0 to 1
2. Generally, P(A|B) is not equal to P(B|A)
3. P(B) must be greater than zero
4. For any fixed event B, the sum of conditional probabilities P(X|B) across all possible outcomes X equals 1

###### Independence

Events A and B are independent if knowing B occurred doesn't change the probability of A. Mathematically:

**If A and B are independent, then P(A|B) = P(A)**

When independence holds, we can simplify to: **P(A ∩ B) = P(A) × P(B)**

This provides a powerful simplification in many probability problems.

###### Chain Rule for Multiple Events

For three events, we can extend our approach:

**P(A,B,C) = P(A|B,C) × P(B|C) × P(C)**

This results from applying the multiplication rule twice:

1. First, P(A,B,C) = P(A|B,C) × P(B,C)
2. Then, substituting P(B,C) = P(B|C) × P(C)

```mermaid
flowchart TD
    A["P(A,B,C)"] --> B["P(A|B,C) × P(B,C)"]
    B --> C["P(A|B,C) × P(B|C) × P(C)"]
    style A fill:#ff5555,stroke:#333,stroke-width:2px
    style B fill:#5588ff,stroke:#333,stroke-width:2px
    style C fill:#55dd55,stroke:#333,stroke-width:2px
```

This chain rule forms the mathematical foundation for Bayesian networks and other probabilistic graphical models by
allowing us to break down complex joint probabilities into simpler conditional components.

###### Example Application

Consider a medical test scenario:

- 1% of the population has a certain disease (P(D) = 0.01)
- The test is 95% accurate for detecting the disease (P(T|D) = 0.95)
- The false positive rate is 10% (P(T|not D) = 0.10)

If someone tests positive, what's the probability they actually have the disease?

We need P(D|T), which we can find using conditional probability: P(D|T) = P(T|D) × P(D) / P(T)

Where P(T) = P(T|D) × P(D) + P(T|not D) × P(not D) = 0.95 × 0.01 + 0.10 × 0.99 = 0.0095 + 0.099 = 0.1085

Therefore: P(D|T) = 0.95 × 0.01 / 0.1085 ≈ 0.088 or about 8.8%

This example illustrates how conditional probability helps us update our beliefs based on new evidence—a concept at the
heart of Bayesian reasoning.

##### Law of Total Probability

The Law of Total Probability allows us to calculate the probability of an event by considering all the ways that event
can occur through mutually exclusive pathways. It's particularly useful when we have information about conditional
probabilities but need the overall probability.

For any partition {B₁, B₂, ..., Bₙ} of the sample space (where the Bᵢ are mutually exclusive and exhaustive):

$$P(A) = \sum_{i=1}^{n} P(A|B_i) \times P(B_i)$$

In the simplest case with just two complementary events B and ¬B:

$$P(A) = P(A|B) \times P(B) + P(A|\neg B) \times P(\neg B)$$

This formula tells us that the total probability of A is the weighted sum of conditional probabilities, where the
weights are the probabilities of the conditioning events.

We can derive the Law of Total Probability using basic set theory and the definition of conditional probability:

1. Start with the fact that the events B₁, B₂, ..., Bₙ form a partition of the sample space, meaning:
    - They are mutually exclusive: $B_i \cap B_j = \emptyset$ for i ≠ j
    - They are exhaustive: $B_1 \cup B_2 \cup ... \cup B_n = \Omega$ (the entire sample space)
2. Any event A can be expressed as the union of its intersections with each B₁:
   $A = A \cap \Omega = A \cap (B_1 \cup B_2 \cup ... \cup B_n) = (A \cap B_1) \cup (A \cap B_2) \cup ... \cup (A \cap B_n)$
3. Since these intersections are mutually exclusive, we can add their probabilities:
   $P(A) = P(A \cap B_1) + P(A \cap B_2) + ... + P(A \cap B_n)$
4. Using the definition of conditional probability, $P(A \cap B_i) = P(A|B_i)P(B_i)$:
   $P(A) = P(A|B_1)P(B_1) + P(A|B_2)P(B_2) + ... + P(A|B_n)P(B_n)$
5. Which gives us the Law of Total Probability: $P(A) = \sum_{i=1}^{n} P(A|B_i)P(B_i)$

For example, to find the probability of having a fever, we might consider whether a person has an infection:

$$P(\text{Fever}) = P(\text{Fever}|\text{Infection}) \times P(\text{Infection}) + P(\text{Fever}|\text{No Infection}) \times P(\text{No Infection})$$

If P(Fever|Infection) = 0.9, P(Infection) = 0.1, P(Fever|No Infection) = 0.05, and P(No Infection) = 0.9, then:

$$P(\text{Fever}) = 0.9 \times 0.1 + 0.05 \times 0.9 = 0.09 + 0.045 = 0.135$$

So the overall probability of fever is 13.5%.

The Law of Total Probability also has a conditional form. For any events A and C, and a partition {B, B̄}, we can derive:

$$P(A|C) = P(A|B,C)P(B|C) + P(A|\bar{B},C)P(\bar{B}|C)$$

This allows us to compute conditional probabilities by considering all possible paths through the partition.

The Law of Total Probability is a fundamental principle that allows us to calculate the total probability of an event by
breaking it down across different scenarios. It provides a systematic way to compute probabilities when direct
calculation might be difficult.

###### Core Definition

For any events A and B, and a set of mutually exclusive and exhaustive events {C, ¬C}:

**P(A|B) = P(A|C,B)P(C|B) + P(A|¬C,B)P(¬C|B)**

Where:

- P(A|B) is the total conditional probability of A given B
- {C, ¬C} form a partition of the sample space meaning:
    - They are mutually exclusive: P(C ∩ ¬C) = 0 (they cannot both occur)
    - They are exhaustive: P(C) + P(¬C) = 1 (one of them must occur)
    - Similarly, P(C|B) + P(¬C|B) = 1 (conditioned on B, one must occur)

###### General Form

This extends to any complete partition {C₁, C₂, ..., Cₙ} of the sample space:

**P(A) = ∑ᵢ P(A|Cᵢ)P(Cᵢ)**

Or for conditional probability:

**P(A|B) = ∑ᵢ P(A|Cᵢ,B)P(Cᵢ|B)**

###### Mathematical Derivation

We can derive the Law of Total Probability from first principles:

1. Starting with the definition of conditional probability for P(A|B): **P(A|B) = P(A,B)/P(B)**
2. Since C and ¬C partition the sample space, we can split P(A,B): P(A,B) = P(A,B,C) + P(A,B,¬C)
3. Substituting into our original equation: P(A|B) = [P(A,B,C) + P(A,B,¬C)]/P(B)
4. Applying the chain rule to each term:
    - P(A,B,C) = P(A|B,C)P(B,C) = P(A|B,C)P(C|B)P(B)
    - P(A,B,¬C) = P(A|B,¬C)P(B,¬C) = P(A|B,¬C)P(¬C|B)P(B)
5. Substituting back and simplifying: P(A|B) = [P(A|B,C)P(C|B)P(B) + P(A|B,¬C)P(¬C|B)P(B)]/P(B) P(A|B) =
   P(A|C,B)P(C|B) + P(A|¬C,B)P(¬C|B)

This demonstrates how we express P(A|B) in terms of conditional probabilities involving C and ¬C.

###### Intuitive Understanding

The Law of Total Probability allows us to break down complex probability problems by considering different scenarios
(the Cᵢ events) separately.

Think of it as a weighted average. Each scenario Cᵢ has:

- A probability of occurring: P(Cᵢ)
- A conditional probability of A given that scenario: P(A|Cᵢ)

We multiply these together for each scenario and sum them up to get the total probability of A.

```mermaid
flowchart TD
    A["Total Probability: P(A)"] --> B["Scenario 1: P(A|C₁)P(C₁)"]
    A --> C["Scenario 2: P(A|C₂)P(C₂)"]
    A --> D["..."]
    A --> E["Scenario n: P(A|Cₙ)P(Cₙ)"]
    style A fill:#ff5555,stroke:#333,stroke-width:2px
    style B fill:#5588ff,stroke:#333,stroke-width:2px
    style C fill:#44cc44,stroke:#333,stroke-width:2px
    style E fill:#ffaa00,stroke:#333,stroke-width:2px
```

###### Practical Example

Consider a medical diagnosis scenario:

- Let A be "patient has disease"
- Let C be "test is positive" and ¬C be "test is negative"

We know:

- P(C|A) = 0.95 (test sensitivity - 95% of sick people test positive)
- P(¬C|¬A) = 0.90 (test specificity - 90% of healthy people test negative)
- P(A) = 0.01 (disease prevalence - 1% of population has disease)

To find the probability a patient has the disease given a positive test (P(A|C)), we can use Bayes' theorem, but first
we need P(C), which we can calculate using the Law of Total Probability:

P(C) = P(C|A)P(A) + P(C|¬A)P(¬A) = 0.95 × 0.01 + (1-0.90) × (1-0.01) = 0.0095 + 0.10 × 0.99 = 0.0095 + 0.099 = 0.1085

Now we can calculate: P(A|C) = P(C|A)P(A)/P(C) = 0.95 × 0.01/0.1085 ≈ 0.088 or about 8.8%

This example demonstrates how the Law of Total Probability helps us solve real-world probability problems by breaking
them down across different scenarios.

###### Applications in Bayesian Networks

The Law of Total Probability forms the foundation for inference in Bayesian networks, where we often need to marginalize
(sum out) hidden variables. It allows us to compute the probability of evidence by considering all possible
configurations of unobserved variables, weighted by their probabilities.

```mermaid
graph LR
    A["P(C|B)"] --> C["P(A|B)"]
    B["P(A|C,B)"] --> C
    D["P(¬C|B)"] --> E["P(A|¬C,B)P(¬C|B)"]
    F["P(A|¬C,B)"] --> E
    C --> G["P(A|B) = P(A|C,B)P(C|B) + P(A|¬C,B)P(¬C|B)"]
    E --> G
    style A fill:#ff9900,stroke:#333,stroke-width:2px
    style B fill:#3399ff,stroke:#333,stroke-width:2px
    style C fill:#ff66cc,stroke:#333,stroke-width:2px
    style D fill:#66cc66,stroke:#333,stroke-width:2px
    style E fill:#9966ff,stroke:#333,stroke-width:2px
    style F fill:#ff5555,stroke:#333,stroke-width:2px
    style G fill:#ffcc00,stroke:#333,stroke-width:2px
```

Understanding the Law of Total Probability is crucial for mastering probabilistic reasoning, as it provides a systematic
approach to tackling complex probability questions by breaking them down into manageable components.

##### Chain Rule of Probability

The Chain Rule of Probability, also known as the general product rule, extends the multiplication rule to multiple
events. It provides a way to break down joint probabilities into a product of conditional probabilities:

$$P(A_1, A_2, ..., A_n) = P(A_1) \times P(A_2|A_1) \times P(A_3|A_1, A_2) \times ... \times P(A_n|A_1, A_2, ..., A_{n-1})$$

This rule is crucial for Bayesian networks because it shows how a joint probability distribution can be decomposed into
simpler conditional probabilities.

For example, the joint probability of three events A, B, and C is:

$$P(A, B, C) = P(A) \times P(B|A) \times P(C|A, B)$$

We can prove the Chain Rule by repeatedly applying the definition of conditional probability. Let's start with the
simplest case of two variables:

1. Start with the definition of conditional probability: $$P(A|B) = \frac{P(A,B)}{P(B)}$$
2. Rearranging this equation: $$P(A,B) = P(A|B)P(B)$$

This gives us the Chain Rule for two variables. Now let's extend to three variables:

1. For three variables A, B, and C, start with: $$P(A,B,C) = P(A|B,C)P(B,C)$$
2. Now expand P(B,C) using the rule we just derived for two variables: $$P(B,C) = P(B|C)P(C)$$
3. Substitute this back into our equation from step 3: $$P(A,B,C) = P(A|B,C)P(B|C)P(C)$$

This pattern continues for any number of variables, which we can prove by induction.

The Chain Rule becomes particularly powerful when combined with conditional independence assumptions. If variables are
conditionally independent, we can simplify the expressions.

For example, if A is conditionally independent of B given C, written as A ⊥ B | C, then:

$$P(A|B,C) = P(A|C)$$

This allows us to simplify chain rule expressions. Consider a Bayesian network where:

- A depends on B and C
- B depends on C
- C is a root node

```mermaid
graph TD
    C --> B
    B --> A
    C -.-> A

    style C fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#bbf,stroke:#333,stroke-width:2px
    style A fill:#bfb,stroke:#333,stroke-width:2px
```

The Chain Rule would give:

$$P(A,B,C) = P(A|B,C) \times P(B|C) \times P(C)$$

If we had additional conditional independence (e.g., if A only depends on B, not on C), we could simplify further:

$$P(A,B,C) = P(A|B) \times P(B|C) \times P(C)$$

In the context of our earlier "Wet Grass" example, we can use the chain rule to express the full joint probability:

$$P(\text{Cloudy}, \text{Rain}, \text{Sprinkler}, \text{Wet}) = P(\text{Cloudy}) \times P(\text{Rain}|\text{Cloudy}) \times P(\text{Sprinkler}|\text{Cloudy}) \times P(\text{Wet}|\text{Rain}, \text{Sprinkler})$$

Note that we exploited the conditional independence of "Rain" and "Sprinkler" given "Cloudy" to simplify the expression.

The Chain Rule of Probability is a fundamental principle that allows us to express joint probabilities as products of
conditional probabilities. This powerful tool helps us break down complex probability scenarios into more manageable
components.

###### Core Definition

For any n events A₁, A₂, ..., Aₙ, the Chain Rule states:

**P(A₁, A₂, ..., Aₙ) = P(A₁) × P(A₂|A₁) × P(A₃|A₁,A₂) × ... × P(Aₙ|A₁,A₂,...,Aₙ₋₁)**

This formula shows that we can decompose the joint probability into a product of conditional probabilities, where each
event is conditioned on all previous events.

###### Mathematical Proof

We can derive the Chain Rule directly from the definition of conditional probability:

1. Starting with two variables and the law of conditional probability:

    P(A|B) = P(A,B)/P(B)

    Rearranging: P(A,B) = P(A|B)P(B)

2. For three variables, we begin with:

    P(A,B,C) = P(A|B,C)P(B,C)

    Here, we're treating (B,C) as a single joint event.

3. We can further expand P(B,C) using the same conditional probability rule:

    P(B,C) = P(B|C)P(C)

4. Substituting this back:

    P(A,B,C) = P(A|B,C)P(B|C)P(C)

This process can be continued for any number of variables, leading to the general form of the Chain Rule.

```mermaid
flowchart TD
    A["Joint Probability: P(A₁,A₂,...,Aₙ)"] --> B["P(A₁)"]
    A --> C["P(A₂|A₁)"]
    A --> D["P(A₃|A₁,A₂)"]
    A --> E["..."]
    A --> F["P(Aₙ|A₁,A₂,...,Aₙ₋₁)"]
    B & C & D & E & F --> G["Multiply all terms"]
    style A fill:#ff5555,stroke:#333,stroke-width:2px
    style B fill:#5588ff,stroke:#333,stroke-width:2px
    style C fill:#44cc44,stroke:#333,stroke-width:2px
    style D fill:#ffaa00,stroke:#333,stroke-width:2px
    style F fill:#cc66ff,stroke:#333,stroke-width:2px
    style G fill:#ff9966,stroke:#333,stroke-width:2px
```

###### Alternative Form

The Chain Rule can also be written in an alternative, yet equivalent form:

**P(A₁,A₂,...,Aₙ) = P(A₁|A₂,...,Aₙ) × P(A₂|A₃,...,Aₙ) × ... × P(Aₙ₋₁|Aₙ) × P(Aₙ)**

This formulation starts by conditioning on the last event and works backward, which can be useful in certain contexts.

###### Chain Rule with Conditioning

The Chain Rule extends naturally to conditional probabilities. For example, for events A, B, C given condition D:

**P(A, B, C | D) = P(A | B, C, D) × P(B | C, D) × P(C | D)**

This formula breaks down the joint conditional probability step by step:

1. **First term - P(C | D)**: The probability of C occurring, given that D has occurred.
2. **Second term - P(B | C, D)**: The probability of B occurring, given that both C and D have occurred.
3. **Third term - P(A | B, C, D)**: The probability of A occurring, given that B, C, and D have all occurred.

This sequential conditioning approach helps us compute complex joint probabilities by breaking them down into simpler
components.

```mermaid
graph LR
    A["P(C|D)"] --> D["P(A,B,C|D)"]
    B["P(B|C,D)"] --> D
    C["P(A|B,C,D)"] --> D
    D --> E["P(A,B,C|D) = P(A|B,C,D) × P(B|C,D) × P(C|D)"]
    style A fill:#ff9900,stroke:#333,stroke-width:2px
    style B fill:#3399ff,stroke:#333,stroke-width:2px
    style C fill:#ff66cc,stroke:#333,stroke-width:2px
    style D fill:#66cc66,stroke:#333,stroke-width:2px
    style E fill:#9966ff,stroke:#333,stroke-width:2px
```

###### Practical Example

Imagine we're modeling the probability of a person's daily activities with events:

- A: Person goes for a run
- B: Person eats breakfast
- C: Person wakes up early
- D: It's a weekday

We want to calculate P(A,B,C|D) - the probability that on a weekday, the person wakes up early, eats breakfast, and goes
for a run.

Using the Chain Rule: P(A,B,C|D) = P(A|B,C,D) × P(B|C,D) × P(C|D)

This allows us to break down our calculation into:

1. P(C|D): Probability of waking up early on a weekday
2. P(B|C,D): Probability of eating breakfast, given they woke up early on a weekday
3. P(A|B,C,D): Probability of going for a run, given they woke up early and ate breakfast on a weekday

Each of these conditional probabilities might be easier to estimate or calculate than trying to determine the joint
probability directly.

###### Significance in Graphical Models

The Chain Rule forms the mathematical foundation for Bayesian networks, where joint distributions are factorized
according to conditional independence relationships represented by a directed acyclic graph. This decomposition
significantly reduces the number of parameters needed to specify complex joint distributions.

By using the Chain Rule in conjunction with conditional independence assumptions, we can represent large,
high-dimensional probability distributions efficiently. For example, in a Bayesian network with n variables, instead of
storing 2ⁿ-1 parameters for the full joint distribution, we only need to store the conditional probability distributions
for each variable given its parents in the graph.

The Chain Rule of Probability is an essential tool that enables us to work with complex probability scenarios by
breaking them down into more manageable components, making it a cornerstone concept in probabilistic reasoning and
graphical models.

##### Bayes' Theorem and Its Applications

Bayes' Theorem is the cornerstone of Bayesian inference. It provides a way to update our beliefs based on new evidence.
The theorem is derived from the definition of conditional probability:

$$P(A|B) = \frac{P(B|A) \times P(A)}{P(B)}$$

Where:

- P(A|B) is the posterior probability: what we want to know after seeing evidence B
- P(B|A) is the likelihood: how probable is the evidence if A is true
- P(A) is the prior probability: our initial belief in A
- P(B) is the evidence: the total probability of observing B

<div align="center"> <img src="images/alarm_bayes_network.png" width="600" height="auto"> <p style="color: #555;">Figure: Application of Bayes' Theorem in the Alarm Network</p> </div>

The denominator $P(B)$ serves as a normalization constant that ensures the posterior probability is a proper probability
(between 0 and 1). We can expand this term using the Law of Total Probability:

$$P(B) = P(B|A) \times P(A) + P(B|\neg A) \times P(\neg A)$$

Where $\neg A$ represents "not A" (the complement of event A).

Substituting this expansion into the original formula:

$$P(A|B) = \frac{P(B|A) \times P(A)}{P(B|A) \times P(A) + P(B|\neg A) \times P(\neg A)}$$

We can prove Bayes' Theorem from the definition of conditional probability:

1. Start with the definition of conditional probability for $P(A|B)$: $$P(A|B) = \frac{P(A \cap B)}{P(B)}$$
2. Similarly, for $P(B|A)$: $$P(B|A) = \frac{P(A \cap B)}{P(A)}$$
3. Rearranging the second equation to solve for $P(A \cap B)$: $$P(A \cap B) = P(B|A) \times P(A)$$
4. Substituting this into the first equation: $$P(A|B) = \frac{P(B|A) \times P(A)}{P(B)}$$

Bayes' theorem is particularly valuable when we know P(B|A) but need P(A|B) - often the case in diagnostic reasoning.
For example, we might know the probability of a positive test result given a disease, but what we want is the
probability of the disease given a positive test.

A canonical example is medical testing:

- P(Disease) = 0.01 (1% of population has the disease)
- P(Positive|Disease) = 0.95 (test is 95% sensitive)
- P(Positive|No Disease) = 0.05 (test is 95% specific)

Using Bayes' theorem to find P(Disease|Positive):

$$P(\text{Disease}|\text{Positive}) = \frac{P(\text{Positive}|\text{Disease}) \times P(\text{Disease})}{P(\text{Positive})}$$

The denominator can be expanded using the law of total probability:

$$P(\text{Positive}) = P(\text{Positive}|\text{Disease}) \times P(\text{Disease}) + P(\text{Positive}|\text{No Disease}) \times P(\text{No Disease})$$
$$P(\text{Positive}) = 0.95 \times 0.01 + 0.05 \times 0.99 = 0.0095 + 0.0495 = 0.059$$

Now we can calculate:

$$P(\text{Disease}|\text{Positive}) = \frac{0.95 \times 0.01}{0.059} \approx 0.161$$

This means despite the 95% test accuracy, the probability of having the disease given a positive test is only about 16%.
This counter-intuitive result, known as the base rate fallacy, highlights the importance of considering prior
probabilities.

Often in practice, we care more about comparing relative probabilities than calculating exact values. In such cases, we
can use the proportional form of Bayes' Theorem:

$$P(A|B) \propto P(B|A) \times P(A)$$

Where the symbol $\propto$ means "proportional to." This form is particularly useful when we're only interested in which
event is more likely, or when the denominator $P(B)$ is complex to calculate.

This problem illustrates a classic application of Bayes' theorem in medical testing. When disease prevalence is very low, even highly accurate tests can lead to surprising results.

###### Problem Analysis

Let's clarify the given information:

- S: Patient is sick (has the disease)
- H: Patient is healthy (does not have the disease)
- +: Test result is positive
- -: Test result is negative

Given probabilities:

- Disease prevalence: P(S) = 1/10,000 = 0.0001
- Healthy prevalence: P(H) = 1 - 0.0001 = 0.9999
- Test sensitivity (true positive rate): P(+|S) = 0.99
- False positive rate: P(+|H) = 0.01 (assuming 99% accuracy means both sensitivity and specificity are 99%)

We want to find P(S|+) - the probability that a person actually has the disease given that they tested positive.

###### Solution Using Bayes' Theorem

Bayes' theorem gives us:

$$P(S|+) = \frac{P(+|S) \times P(S)}{P(+)}$$

Where P(+) is the total probability of a positive test result, calculated using the Law of Total Probability:

$$P(+) = P(+|S) \times P(S) + P(+|H) \times P(H)$$

Substituting our values:

$$P(+) = 0.99 \times 0.0001 + 0.01 \times 0.9999 = 0.000099 + 0.009999 = 0.010098$$

Now we can calculate P(S|+):

$$P(S|+) = \frac{0.99 \times 0.0001}{0.010098} = \frac{0.000099}{0.010098} \approx 0.0098 \approx 0.98%$$

This means that even with a positive test result, there's only about a 1% chance that the person actually has the disease.

###### Intuitive Explanation With Expected Numbers

Let's consider what would happen in a population of 1,000,000 people:

- Number of sick people: 1,000,000 × 0.0001 = 100
- Number of healthy people: 1,000,000 × 0.9999 = 999,900

Of these:

- Sick people with positive tests (true positives): 100 × 0.99 = 99
- Sick people with negative tests (false negatives): 100 × 0.01 = 1
- Healthy people with positive tests (false positives): 999,900 × 0.01 = 9,999
- Healthy people with negative tests (true negatives): 999,900 × 0.99 = 989,901

Total positive test results: 99 + 9,999 = 10,098

Therefore:

- P(S|+) = 99/10,098 ≈ 0.0098 ≈ 0.98%

```mermaid
flowchart TD
    A["Population: 1,000,000"] --> B["Sick: 100"]
    A --> C["Healthy: 999,900"]
    B --> D["True+: 99"]
    B --> E["False-: 1"]
    C --> F["False+: 9,999"]
    C --> G["True-: 989,901"]
    D --> H["Positive Tests: 10,098"]
    F --> H
    style A fill:#ff9900,stroke:#333,stroke-width:2px
    style B fill:#3399ff,stroke:#333,stroke-width:2px
    style C fill:#ff66cc,stroke:#333,stroke-width:2px
    style D fill:#66cc66,stroke:#333,stroke-width:2px
    style F fill:#ff5555,stroke:#333,stroke-width:2px
    style H fill:#ffaa00,stroke:#333,stroke-width:2px
```

###### Why This Result Is Counterintuitive

This result often surprises people. How can a 99% accurate test give a positive result that's only 1% likely to be correct? This is known as the "base rate fallacy" or "prevalence effect."

The key insight is that when a disease is very rare (low prevalence), even a small false positive rate can lead to many more false positives than true positives in absolute numbers.

Let's put it another way: Of all positive test results, the vast majority (9,999 out of 10,098, or about 99%) are false positives, simply because there are so many more healthy people than sick people in the population.

###### Implications For Medical Testing

This example demonstrates why doctors often:

1. Use multiple tests for rare conditions
2. Only test people with symptoms or risk factors (to increase the pre-test probability)
3. Carefully explain test results in context of disease prevalence

The calculation we performed is critical in medical decision-making, helping doctors understand the true predictive value of positive test results, especially for rare conditions.

###### Mathematical Formulation

The general form of what we've calculated is:

$$P(S|+) = \frac{P(S)P(+|S)}{P(S)P(+|S) + P(H)P(+|H)}$$

This equation shows that the posterior probability depends on:

1. The prior probability (disease prevalence)
2. The test's sensitivity (true positive rate)
3. The test's false positive rate

When the disease is rare, P(S) is very small, and even with a high sensitivity and low false positive rate, the posterior probability can remain surprisingly low.

This problem illustrates the critical importance of considering base rates when interpreting test results, a fundamental concept in probabilistic reasoning and medical diagnostics.

##### Independence and Conditional Independence

Two events A and B are independent if the occurrence of one doesn't affect the probability of the other:

$$P(A|B) = P(A)$$

Equivalently:

$$P(A \cap B) = P(A) \times P(B)$$

Independence is a powerful simplifying assumption in probabilistic models. When events are independent, we can simply
multiply their probabilities to find joint probabilities.

Conditional independence is a more nuanced concept. Events A and B are conditionally independent given event C if, once
we know C has occurred, information about B doesn't change our beliefs about A:

$$P(A|B,C) = P(A|C)$$

This is written as A ⊥ B | C (A is independent of B given C).

Conditional independence is central to Bayesian networks. In the network structure, a node is conditionally independent
of its non-descendants given its parents. This property enables the compact factorization of joint distributions.

Consider three types of conditional independence patterns in Bayesian networks:

1. **Causal chain (A → B → C)**:
    - A and C are dependent
    - A and C are conditionally independent given B
    - Example: Disease → Symptom → Treatment
2. **Common cause (A ← B → C)**:
    - A and C are dependent
    - A and C are conditionally independent given B
    - Example: Fever ← Infection → Cough
3. **Common effect (A → C ← B)**:
    - A and B are independent
    - A and B are conditionally dependent given C (explaining away)
    - Example: Rain → Wet Grass ← Sprinkler

```mermaid
graph TD
    subgraph "Causal Chain"
    A1[A] --> B1[B]
    B1 --> C1[C]
    end

    subgraph "Common Cause"
    B2[B] --> A2[A]
    B2 --> C2[C]
    end

    subgraph "Common Effect (v-structure)"
    A3[A] --> C3[C]
    B3[B] --> C3
    end
```

The v-structure (common effect) exhibits a particularly interesting property called "explaining away." If we observe the
effect C, then learning about cause A changes our beliefs about cause B, even though A and B were initially independent.
For example, if we know the grass is wet and we learn it rained, the probability of the sprinkler having been on
decreases.

Understanding these patterns of independence is crucial for both constructing Bayesian networks and performing efficient
inference in them. The conditional independence relationships encoded in the network structure allow us to reduce the
number of parameters needed and enable more efficient algorithms for probabilistic reasoning.

It's important to understand that absolute independence and conditional independence don't imply each other:

1. **A ⊥ B does not imply A ⊥ B|C**: Variables that are absolutely independent can become dependent when conditioning on
   another variable.
2. **A ⊥ B|C does not imply A ⊥ B**: Variables that are conditionally independent given C might still be dependent when
   considered without C.

These relationships underscore the complex ways that information can flow through probabilistic models, and they form
the foundation for understanding the behavior of Bayesian networks in practice.

#### Working with Probability Distributions

##### Discrete Probability Distributions

Discrete probability distributions model random variables that can take only distinct, separate values. These are
fundamental building blocks for probabilistic graphical models, especially when modeling categorical variables like
disease states, weather conditions, or parts of speech.

A discrete probability distribution assigns a probability to each possible value of the random variable, with the total
probability summing to 1. For a random variable X with possible values {x₁, x₂, ..., xₙ}, the probability mass function
P(X) must satisfy:

1. Non-negativity: P(X = xᵢ) ≥ 0 for all i
2. Normalization: ∑ᵢ P(X = xᵢ) = 1

Common discrete distributions include:

- **Bernoulli distribution**: Models a binary outcome (success/failure) with probability p of success
    - P(X = 1) = p
    - P(X = 0) = 1-p
    - Example: Modeling whether a patient has a disease
- **Binomial distribution**: Models the number of successes in n independent Bernoulli trials
    - P(X = k) = (n choose k) × pᵏ × (1-p)ⁿ⁻ᵏ
    - Example: Number of patients who recover out of 10 treated
- **Categorical distribution**: Generalizes Bernoulli to more than two outcomes
    - P(X = xᵢ) = pᵢ where ∑ᵢ pᵢ = 1
    - Example: Modeling parts of speech (noun, verb, adjective, etc.)

In Bayesian networks, each node typically has a discrete probability distribution conditioned on its parents. For root
nodes, we specify a prior distribution; for child nodes, we specify a conditional distribution for each combination of
parent values.

For example, in our alarm Bayesian network, the "Alarm" node has a conditional probability distribution P(Alarm |
Burglary, Earthquake) that specifies the probability of the alarm being triggered for each combination of its parent
values (whether a burglary occurred and whether there was an earthquake).

```mermaid
graph TD
    B[Burglary] --> A[Alarm]
    E[Earthquake] --> A
    A --> J[John Calls]
    A --> M[Mary Calls]

    style B fill:#f9f,stroke:#333,stroke-width:1px
    style E fill:#f9f,stroke:#333,stroke-width:1px
    style A fill:#bbf,stroke:#333,stroke-width:1px
    style J fill:#bfb,stroke:#333,stroke-width:1px
    style M fill:#bfb,stroke:#333,stroke-width:1px
```

In this network, each node has a discrete distribution:

- Burglary: Bernoulli (yes/no)
- Earthquake: Bernoulli (yes/no)
- Alarm: Conditional Bernoulli given Burglary and Earthquake
- John Calls: Conditional Bernoulli given Alarm
- Mary Calls: Conditional Bernoulli given Alarm

The power of discrete distributions lies in their simplicity and interpretability, making them ideal for modeling many
real-world phenomena in a probabilistic graphical framework.

##### Joint and Marginal Probabilities

Joint probability distributions model the probabilities of multiple random variables simultaneously. For two discrete
random variables X and Y, the joint distribution P(X,Y) gives the probability of each combination of values (x,y).

For example, in a medical diagnosis context, we might have:

```
P(Disease=present, Symptom=present) = 0.08
P(Disease=present, Symptom=absent) = 0.02
P(Disease=absent, Symptom=present) = 0.12
P(Disease=absent, Symptom=absent) = 0.78
```

This joint distribution contains complete information about the probabilistic relationship between Disease and Symptom.
From it, we can derive marginal and conditional distributions.

The marginal distribution of a single variable is obtained by summing over all values of the other variables. For
example:

$$P(X = x) = \sum_y P(X = x, Y = y)$$

Using our example:

$$P(\text{Disease=present}) = P(\text{Disease=present, Symptom=present}) + P(\text{Disease=present, Symptom=absent}) = 0.08 + 0.02 = 0.10$$

$$P(\text{Symptom=present}) = P(\text{Disease=present, Symptom=present}) + P(\text{Disease=absent, Symptom=present}) = 0.08 + 0.12 = 0.20$$

Marginalization is a fundamental operation in probabilistic inference. When we have evidence about some variables in a
Bayesian network and want to infer others, we often need to sum out (marginalize) the hidden variables.

For multiple variables, the joint distribution grows exponentially with the number of variables. For n binary variables,
we need 2ⁿ values to specify the full joint distribution. This is where Bayesian networks become powerful: they allow us
to represent the joint distribution more compactly by exploiting conditional independence relationships.

<div align="center"> <img src="images/alarm_bayes_network.png" width="600" height="auto"> <p style="color: #555;">Figure: Joint probability distribution factored according to a Bayesian network</p> </div>

In the alarm network above, the full joint distribution P(Burglary, Earthquake, Alarm, JohnCalls, MaryCalls) would
require 2⁵ = 32 parameters. However, using the factorization provided by the Bayesian network structure, we only need
1 + 1 + 4 + 2 + 2 = 10 parameters, a significant reduction in complexity.

##### Calculating Conditional Probabilities

Conditional probabilities can be derived from joint probabilities using the definition:

$$P(X|Y) = \frac{P(X,Y)}{P(Y)}$$

For each value y of Y, P(X|Y=y) is a probability distribution over X. Continuing our medical example:

$$P(\text{Disease=present}|\text{Symptom=present}) = \frac{P(\text{Disease=present, Symptom=present})}{P(\text{Symptom=present})}$$

$$P(\text{Disease=present}|\text{Symptom=present}) = \frac{0.08}{0.08 + 0.12} = \frac{0.08}{0.20} = 0.40$$

This tells us that if a patient has the symptom, there's a 40% chance they have the disease.

In Bayesian networks, conditional probability tables (CPTs) explicitly represent these conditional distributions. For
each node, its CPT specifies the distribution over its values for each combination of parent values.

For example, in our alarm network, the CPT for the Alarm node might look like:

| Burglary | Earthquake | P(Alarm=true) | P(Alarm=false) |
| -------- | ---------- | ------------- | -------------- |
| true     | true       | 0.95          | 0.05           |
| true     | false      | 0.94          | 0.06           |
| false    | true       | 0.29          | 0.71           |
| false    | false      | 0.001         | 0.999          |

This table shows, for instance, that when both a burglary and an earthquake occur, there's a 95% chance the alarm will
sound.

Note that while we can calculate conditional probabilities from joint probabilities, a key insight of Bayesian networks
is that we can reconstruct the full joint distribution if we know the conditional probabilities following the network
structure:

$$P(X_1, X_2, ..., X_n) = \prod_{i=1}^{n} P(X_i | \text{Parents}(X_i))$$

This allows us to compute any conditional probability query by first computing the relevant joint probabilities and then
normalizing.

##### Normalization Methods

Normalization is a fundamental operation in Bayesian inference. When updating beliefs based on evidence, we often first
calculate proportional probabilities (unnormalized) and then normalize them to ensure they sum to 1.

For a discrete probability distribution P'(X) that is proportional to the true distribution P(X), we normalize by
dividing by the sum:

$$P(X = x_i) = \frac{P'(X = x_i)}{\sum_j P'(X = x_j)}$$

The normalization factor, often denoted by α or η, is just the reciprocal of this sum:

$$P(X = x_i) = \alpha \times P'(X = x_i) \text{ where } \alpha = \frac{1}{\sum_j P'(X = x_j)}$$

This process appears frequently in Bayesian inference. When applying Bayes' theorem:

$$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$$

We can compute P(B|A)P(A) for each value of A, and then normalize to find P(A|B).

Let's derive the normalization constant step by step using Bayes' Rule for a binary variable A. We start with the
unnormalized forms:

$$P'(A|B) = P(B|A)P(A)$$ $$P'(\neg A|B) = P(B|\neg A)P(\neg A)$$

Where P' indicates unnormalized probabilities.

Since probabilities must sum to 1: $$P(A|B) + P(\neg A|B) = 1$$

If we define a normalization constant η: $$P(A|B) = \eta \times P'(A|B)$$ $$P(\neg A|B) = \eta \times P'(\neg A|B)$$

Then: $$\eta \times P'(A|B) + \eta \times P'(\neg A|B) = 1$$ $$\eta \times [P'(A|B) + P'(\neg A|B)] = 1$$
$$\eta = \frac{1}{P'(A|B) + P'(\neg A|B)}$$ $$\eta = \frac{1}{P(B|A)P(A) + P(B|\neg A)P(\neg A)}$$
$$\eta = \frac{1}{P(B)}$$

This shows that η = 1/P(B), confirming that our normalization approach is consistent with Bayes' Theorem.

Example: Consider a simple diagnostic test for a disease with:

- Prior: P(Disease) = 0.01
- Likelihood: P(Positive|Disease) = 0.95, P(Positive|No Disease) = 0.05

For a positive test result:

1. Unnormalized posterior:
    - P'(Disease|Positive) = P(Positive|Disease) × P(Disease) = 0.95 × 0.01 = 0.0095
    - P'(No Disease|Positive) = P(Positive|No Disease) × P(No Disease) = 0.05 × 0.99 = 0.0495
2. Normalization:
    - Sum = 0.0095 + 0.0495 = 0.059
    - P(Disease|Positive) = 0.0095 / 0.059 ≈ 0.161
    - P(No Disease|Positive) = 0.0495 / 0.059 ≈ 0.839

This approach of calculating unnormalized posteriors and then normalizing is often more practical than directly
computing the denominator in Bayes' theorem, especially in complex models with many variables.

##### Complex Probability Examples

Let's examine a more complex example that integrates multiple concepts: the famous "Monty Hall problem."

In this game show scenario:

- There are three doors (A, B, C)
- A car is behind one door, goats behind the others
- The contestant picks a door, e.g., door A
- The host (who knows where the car is) opens another door with a goat, e.g., door C
- The contestant can stick with door A or switch to door B
- The question is: Should they switch?

We can solve this using Bayes' theorem:

Let:

- Cₐ = Car is behind door A
- Cᵦ = Car is behind door B
- Cᶜ = Car is behind door C
- H₍c₎ = Host opens door C

We want to compare P(Cₐ|H₍c₎) versus P(Cᵦ|H₍c₎)

For P(Cₐ|H₍c₎): $$P(C_a|H_{(c)}) = \frac{P(H_{(c)}|C_a) \times P(C_a)}{P(H_{(c)})}$$

- P(Cₐ) = 1/3 (prior)
- P(H₍c₎|Cₐ) = 1/2 (host chooses randomly between B and C)
- P(H₍c₎) = normalization factor

For P(Cᵦ|H₍c₎): $$P(C_b|H_{(c)}) = \frac{P(H_{(c)}|C_b) \times P(C_b)}{P(H_{(c)})}$$

- P(Cᵦ) = 1/3 (prior)
- P(H₍c₎|Cᵦ) = 1 (host must choose C)
- P(H₍c₎) = same normalization factor

Comparing the unnormalized posteriors:

- P'(Cₐ|H₍c₎) = 1/2 × 1/3 = 1/6
- P'(Cᵦ|H₍c₎) = 1 × 1/3 = 1/3

After normalization:

- P(Cₐ|H₍c₎) = 1/3
- P(Cᵦ|H₍c₎) = 2/3

Therefore, switching doubles the probability of winning!

Another compelling example is the "Two-Test Cancer Scenario":

A patient takes two tests for a rare disease (1% prevalence). Each test is 90% sensitive (90% true positive rate) and
80% specific (80% true negative rate). Both tests come back positive.

What is the probability the patient has the disease?

Using Bayes' theorem with multiple pieces of evidence:

$$P(C|T_1=+,T_2=+) = \frac{P(T_1=+,T_2=+|C) \times P(C)}{P(T_1=+,T_2=+)}$$

Assuming the tests are conditionally independent given disease status:

$$P(T_1=+,T_2=+|C) = P(T_1=+|C) \times P(T_2=+|C) = 0.9 \times 0.9 = 0.81$$
$$P(T_1=+,T_2=+|¬C) = P(T_1=+|¬C) \times P(T_2=+|¬C) = 0.2 \times 0.2 = 0.04$$

Calculating the unnormalized posterior:

- P'(C|T₁=+,T₂=+) = 0.81 × 0.01 = 0.0081
- P'(¬C|T₁=+,T₂=+) = 0.04 × 0.99 = 0.0396

After normalization:

- P(C|T₁=+,T₂=+) = 0.0081 / (0.0081 + 0.0396) ≈ 0.17

Despite two positive tests, the post-test probability is only 17% due to the low prevalence of the disease. This
illustrates the challenge of diagnostic testing for rare conditions and the importance of considering both
sensitivity/specificity and base rates.

Let's consider one more complex example: the "Office Attendance and Clothing Color" problem:

Alex comes to the office 3 days a week and Brenda comes to the office 1 day a week. We observed a person wearing a red
sweater. Alex wears red 2 times a week and Brenda wears red 3 times a week. The scenario assumes they work remotely from
home the rest of the days and can wear red even when working from home.

Information:

- Alex: Comes to office 3/5 days = 0.6 (Prior P(A))
- Alex: Wears red 2/5 times = 0.4 (P(R|A))
- Brenda: Comes to office 1/5 days = 0.2 (Prior P(B))
- Brenda: Wears red 3/5 times = 0.6 (P(R|B))
- Red wearing is independent of office attendance

We need to find P(A|R) - the probability it was Alex given we observed a red sweater.

Using Bayes' Theorem: $$P(A|R) = \frac{P(R|A) \times P(A)}{P(R)}$$

Where the denominator P(R) is calculated using the Law of Total Probability:
$$P(R) = P(R|A) \times P(A) + P(R|B) \times P(B)$$ $$P(R) = 0.4 \times 0.6 + 0.6 \times 0.2 = 0.24 + 0.12 = 0.36$$

Now we can calculate: $$P(A|R) = \frac{0.4 \times 0.6}{0.36} = \frac{0.24}{0.36} = \frac{2}{3} \approx 66.7%$$

This means there's a 66.7% probability that the person we saw wearing red was Alex.

```mermaid
graph TD
    Event --> |"P(A)=0.6"| A[Alex]
    Event --> |"P(B)=0.2"| B[Brenda]
    A --> |"P(R|A)=0.4"| R1[Red]
    A --> |"P(not R|A)=0.6"| NR1[Not Red]
    B --> |"P(R|B)=0.6"| R2[Red]
    B --> |"P(not R|B)=0.4"| NR2[Not Red]

    style Event fill:#e0f7fa,stroke:#006064,stroke-width:2px
    style A fill:#bbdefb,stroke:#1565c0,stroke-width:2px
    style B fill:#bbdefb,stroke:#1565c0,stroke-width:2px
    style R1 fill:#ffccbc,stroke:#bf360c,stroke-width:2px
    style R2 fill:#ffccbc,stroke:#bf360c,stroke-width:2px
    style NR1 fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px
    style NR2 fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px

    linkStyle 0 stroke:#1565c0,stroke-width:2px
    linkStyle 1 stroke:#1565c0,stroke-width:2px
    linkStyle 2 stroke:#bf360c,stroke-width:2px
    linkStyle 3 stroke:#2e7d32,stroke-width:2px
    linkStyle 4 stroke:#bf360c,stroke-width:2px
    linkStyle 5 stroke:#2e7d32,stroke-width:2px
```

These examples demonstrate how probability theory provides a rigorous framework for reasoning under uncertainty,
especially when dealing with multiple sources of evidence or counterintuitive situations. The principles of conditional
probability, Bayes' theorem, and normalization give us powerful tools to update our beliefs as new evidence arrives,
making them essential for both probabilistic graphical models and real-world decision making.

This problem requires us to determine the probability that a person wearing a red sweater at the office is Alex, given the information we have about both Alex and Brenda's office attendance and clothing habits.

###### Problem Analysis

Let's clarify the given information:

For Alex (A):

- Comes to office 3 days out of 5 work days: P(A) = 3/5 = 0.6
- Wears red 2 days out of 5: P(R|A) = 2/5 = 0.4
- Red sweater wearing is independent of office attendance

For Brenda (B):

- Comes to office 1 day out of 5 work days: P(B) = 1/5 = 0.2
- Wears red 3 days out of 5: P(R|B) = 3/5 = 0.6
- Red sweater wearing is independent of office attendance

I notice that we need to adjust the initial probabilities, as it appears there's a discrepancy in the setup:

- If Alex comes 3/5 days and Brenda comes 1/5 days, P(A) = 0.6 and P(B) = 0.2
- However, if we're looking at conditional probability given someone was at the office, we need to normalize these values:
  - P(A) = 3/(3+1) = 3/4 = 0.75
  - P(B) = 1/(3+1) = 1/4 = 0.25

This adjustment makes sense because we're given the condition that we saw a person at the office, so we're working within the subset of events where either Alex or Brenda is present at the office.

###### Solution Using Bayes' Theorem

We want to find P(A|R) - the probability it was Alex given we saw someone wearing red.

Bayes' Theorem states:

$$P(A|R) = \frac{P(R|A) \times P(A)}{P(R)}$$

Where P(R) is the total probability of seeing red, calculated using the Law of Total Probability:

$$P(R) = P(R|A) \times P(A) + P(R|B) \times P(B)$$

Substituting our values:

$$P(R) = 0.4 \times 0.75 + 0.6 \times 0.25 = 0.3 + 0.15 = 0.45$$

Now we can calculate P(A|R):

$$P(A|R) = \frac{0.4 \times 0.75}{0.45} = \frac{0.3}{0.45} = \frac{2}{3} \approx 66.7%$$

```mermaid
flowchart TD
    A["Office Visitor"] -->|"P(A)=0.75"| B["Alex"]
    A -->|"P(B)=0.25"| C["Brenda"]
    B -->|"P(R|A)=0.4"| D["Red Sweater"]
    B -->|"P(R'|A)=0.6"| E["Not Red"]
    C -->|"P(R|B)=0.6"| D
    C -->|"P(R'|B)=0.4"| E
    style A fill:#ff9900,stroke:#333,stroke-width:2px
    style B fill:#3399ff,stroke:#333,stroke-width:2px
    style C fill:#ff66cc,stroke:#333,stroke-width:2px
    style D fill:#66cc66,stroke:#333,stroke-width:2px
    style E fill:#9966ff,stroke:#333,stroke-width:2px
```

###### Verification

We can verify our result by checking that P(A|R) + P(B|R) = 1:

$$P(B|R) = \frac{P(R|B) \times P(B)}{P(R)} = \frac{0.6 \times 0.25}{0.45} = \frac{0.15}{0.45} = \frac{1}{3} \approx 33.3%$$

And indeed: 66.7% + 33.3% = 100%

###### Mathematical Formulation

The general form of what we've calculated can be expressed as:

$$P(A|R) = \frac{P(A)P(R|A)}{P(A)P(R|A) + P(B)P(R|B)}$$ $$P(B|R) = \frac{P(B)P(R|B)}{P(A)P(R|A) + P(B)P(R|B)}$$

This is a direct application of Bayes' theorem where:

- The prior probabilities P(A) and P(B) represent our beliefs about who is likely to be at the office
- The likelihoods P(R|A) and P(R|B) represent the probabilities of wearing red given the person
- The posterior probability P(A|R) represents our updated belief after observing the red sweater

###### Key Insights

1. **Independence Assumption**: The problem assumes that wearing a red sweater is independent of coming to the office. This simplifies our calculations as we don't need to consider conditional dependencies between these events.
2. **Prior Adjustment**: We adjusted the prior probabilities to reflect the condition that we saw someone at the office, which means we're already working in a restricted probability space.
3. **Likelihood Ratio**: The ratio of P(A|R) to P(B|R) depends on both the prior odds (P(A)/P(B) = 3) and the likelihood ratio (P(R|A)/P(R|B) = 2/3). The prior favors Alex, but the likelihood favors Brenda. The combination of these factors gives us our final result.
4. **Posterior Probability**: Despite Brenda being more likely to wear red (60% vs 40% for Alex), Alex is still more likely to be the person we saw because Alex comes to the office much more frequently.

The solution indicates that there's approximately a 66.7% chance that the person wearing the red sweater at the office was Alex.
