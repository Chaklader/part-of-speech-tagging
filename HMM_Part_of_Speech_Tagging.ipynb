{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Project: Part of Speech Tagging with Hidden Markov Models \n",
    "\n",
    "### Introduction\n",
    "\n",
    "Part of speech tagging is the process of determining the syntactic category of a word from the words in its surrounding context. It is often used to help disambiguate natural language phrases because it can be done quickly with high accuracy. Tagging can be used for many NLP tasks like determining correct pronunciation during speech synthesis (for example, _dis_-count as a noun vs dis-_count_ as a verb), for information retrieval, and for word sense disambiguation.\n",
    "\n",
    "In this notebook, you'll use the [Pomegranate](http://pomegranate.readthedocs.io/) library to build a hidden Markov model for part of speech tagging using a \"universal\" tagset. Hidden Markov models have been able to achieve [>96% tag accuracy with larger tagsets on realistic text corpora](http://www.coli.uni-saarland.de/~thorsten/publications/Brants-ANLP00.pdf). Hidden Markov models have also been used for speech recognition and speech generation, machine translation, gene recognition for bioinformatics, and human gesture recognition for computer vision, and more. \n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/post-hmm.png\" width=\"800\" height=auto>\n",
    "    <figcaption>fig: Hidden Markov Model for Part of Speech Tagging</figcaption>\n",
    "<div>\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Road Ahead\n",
    "You must complete Steps 1-3 below to pass the project. The section on Step 4 includes references & resources you can use to further explore HMM taggers.\n",
    "\n",
    "- [Step 1](#Step-1:-Read-and-preprocess-the-dataset): Review the provided interface to load and access the text corpus\n",
    "- [Step 2](#Step-2:-Build-a-Most-Frequent-Class-tagger): Build a Most Frequent Class tagger to use as a baseline\n",
    "- [Step 3](#Step-3:-Build-an-HMM-tagger): Build an HMM Part of Speech tagger and compare to the MFC baseline\n",
    "- [Step 4](#Step-4:-[Optional]-Improving-model-performance): (Optional) Improve the HMM tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:35:38.693587Z",
     "start_time": "2024-10-09T14:35:38.689072Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Jupyter \"magic methods\" -- only need to be run once per kernel restart\n",
    "%load_ext autoreload\n",
    "# %aimport helpers, tests\n",
    "\n",
    "%aimport helpers\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:35:45.395969Z",
     "start_time": "2024-10-09T14:35:45.392712Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import python modules -- this cell needs to be run again if you make changes to any of the files\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from itertools import chain\n",
    "from collections import Counter, defaultdict\n",
    "from helpers import show_model, Dataset\n",
    "# from pomegranate import State, HiddenMarkovModel, DiscreteDistribution\n",
    "\n",
    "from pomegranate.hmm import DenseHMM\n",
    "from pomegranate.distributions import Categorical\n",
    "# Note: State and HiddenMarkovModel classes no longer exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "##### Step 1: Read and preprocess the dataset\n",
    "\n",
    "We'll start by reading in a text corpus and splitting it into a training and testing dataset. The data set is a copy of the [Brown corpus](https://en.wikipedia.org/wiki/Brown_Corpus) (originally from the [NLTK](https://www.nltk.org/) library) that has already been pre-processed to only include the [universal tagset](https://arxiv.org/pdf/1104.2086.pdf). You should expect to get slightly higher accuracy using this simplified tagset than the same model would achieve on a larger tagset like the full [Penn treebank tagset](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html), but the process you'll follow would be the same.\n",
    "\n",
    "The `Dataset` class provided in helpers.py will read and parse the corpus. You can generate your own datasets compatible with the reader by writing them to the following format. The dataset is stored in plaintext as a collection of words and corresponding tags. Each sentence starts with a unique identifier on the first line, followed by one tab-separated word/tag pair on each following line. Sentences are separated by a single blank line.\n",
    "\n",
    "Example from the Brown corpus. \n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "\\texttt{b100-38532} & & \\text{\\# Sentence identifier (unique ID)} \\\\\n",
    "\\texttt{Perhaps} & \\texttt{ADV} & \\text{\\# word[TAB]tag pairs} \\\\\n",
    "\\texttt{it} & \\texttt{PRON} & \\\\\n",
    "\\texttt{was} & \\texttt{VERB} & \\\\\n",
    "\\texttt{right} & \\texttt{ADJ} & \\\\\n",
    "\\texttt{;} & \\texttt{.} & \\\\\n",
    "\\texttt{;} & \\texttt{.} & \\\\\n",
    "& & \\\\\n",
    "& & \\text{\\# Blank line separates sentences} \\\\\n",
    "\\texttt{b100-35577} & & \\text{\\# Next sentence starts} \\\\\n",
    "\\texttt{...} & & \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "##### Understanding the Dataset Structure and Preprocessing\n",
    "\n",
    "##### What the Brown Corpus Is\n",
    "\n",
    "The Brown corpus is a foundational dataset in computational linguistics containing over one million words of American English text from various sources (newspapers, novels, academic papers, etc.). For this part-of-speech tagging task, the corpus has been simplified to use the **Universal POS tagset**, which reduces the complexity from the original Penn Treebank's 45+ tags to just 12 universal categories:\n",
    "\n",
    "- **NOUN** - nouns\n",
    "- **VERB** - verbs  \n",
    "- **ADJ** - adjectives\n",
    "- **ADV** - adverbs\n",
    "- **PRON** - pronouns\n",
    "- **DET** - determiners\n",
    "- **ADP** - adpositions (prepositions)\n",
    "- **NUM** - numerals\n",
    "- **CONJ** - conjunctions\n",
    "- **PRT** - particles\n",
    "- **.** - punctuation\n",
    "- **X** - other/unknown\n",
    "\n",
    "##### Dataset File Format Explanation\n",
    "\n",
    "The corpus uses a specific plaintext format designed for sequence labeling tasks:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "\\texttt{b100-38532} & & \\text{\\# Sentence identifier (unique ID)} \\\\\n",
    "\\texttt{Perhaps} & \\texttt{ADV} & \\text{\\# word[TAB]tag pairs} \\\\\n",
    "\\texttt{it} & \\texttt{PRON} & \\\\\n",
    "\\texttt{was} & \\texttt{VERB} & \\\\\n",
    "\\texttt{right} & \\texttt{ADJ} & \\\\\n",
    "\\texttt{;} & \\texttt{.} & \\\\\n",
    "\\texttt{;} & \\texttt{.} & \\\\\n",
    "& & \\\\\n",
    "& & \\text{\\# Blank line separates sentences} \\\\\n",
    "\\texttt{b100-35577} & & \\text{\\# Next sentence starts} \\\\\n",
    "\\texttt{...} & & \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "**Key Format Rules:**\n",
    "- Each sentence begins with a unique identifier\n",
    "- Word-tag pairs are separated by tabs (`\\t`)\n",
    "- One word-tag pair per line\n",
    "- Sentences are separated by blank lines\n",
    "- This format enables easy parsing for supervised learning\n",
    "\n",
    "\n",
    "### Understanding the Dataset Loading Code\n",
    "\n",
    "```python\n",
    "data = Dataset(\"data/tags-universal.txt\", \"data/brown-universal.txt\", train_test_split=0.8)\n",
    "\n",
    "print(\"There are {} sentences in the corpus.\".format(len(data)))\n",
    "print(\"There are {} sentences in the training set.\".format(len(data.training_set)))\n",
    "print(\"There are {} sentences in the testing set.\".format(len(data.testing_set)))\n",
    "\n",
    "assert len(data) == len(data.training_set) + len(data.testing_set), \\\n",
    "       \"The number of sentences in the training set + testing set should sum to the number of sentences in the corpus\"\n",
    "```\n",
    "\n",
    "**What This Code Does:**\n",
    "\n",
    "1. **Dataset Initialization**: Creates a Dataset object that:\n",
    "   - Reads the tag vocabulary from `tags-universal.txt`\n",
    "   - Parses the corpus from `data/brown-universal.txt`\n",
    "   - Splits data into 80% training, 20% testing\n",
    "\n",
    "2. **Data Validation**: The assertion ensures data integrity by verifying that:\n",
    "   - Total sentences = Training sentences + Testing sentences\n",
    "   - No data is lost during the splitting process\n",
    "\n",
    "3. **Train-Test Split Strategy**: Uses temporal or sequential splitting (not random) to:\n",
    "   - Preserve sentence ordering\n",
    "   - Avoid data leakage between training and testing\n",
    "   - Simulate real-world deployment conditions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tags_from_corpus(corpus_file_path):\n",
    "    \"\"\"Extract unique POS tags from the Brown corpus file.\"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Check if tags file already exists\n",
    "    if os.path.exists('data/tags-universal.txt'):\n",
    "        return\n",
    "        \n",
    "    tags = set()\n",
    "    \n",
    "    with open(corpus_file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            # Skip empty lines and sentence identifiers\n",
    "            if line and '\\t' in line:\n",
    "                word, tag = line.split('\\t')\n",
    "                tags.add(tag)\n",
    "    \n",
    "    # Write tags to file in the data directory\n",
    "    with open('data/tags-universal.txt', 'w', encoding='utf-8') as tag_file:\n",
    "        for tag in sorted(tags):\n",
    "            tag_file.write(tag + '\\n')\n",
    "    \n",
    "    print(f\"Found {len(tags)} unique tags: {sorted(tags)}\")\n",
    "    return sorted(tags)\n",
    "\n",
    "# Generate the tags file\n",
    "extract_tags_from_corpus(\"data/brown-universal.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "##### Understanding the Dataset Interface\n",
    "\n",
    "The `Dataset` class provides a structured interface for accessing corpus data with built-in train-test splitting functionality. Both the main `Dataset` and its `Subset` components share a common API for consistent data access patterns.\n",
    "\n",
    "### Class Hierarchy and Attributes\n",
    "\n",
    "#### Dataset-Specific Attributes\n",
    "```python\n",
    "training_set    # Subset object containing training sentences (default: 80%)\n",
    "testing_set     # Subset object containing testing sentences (default: 20%)\n",
    "```\n",
    "\n",
    "#### Shared Attributes (Dataset & Subset)\n",
    "```python\n",
    "sentences       # Dictionary mapping sentence_id -> Sentence(words, tags)\n",
    "keys           # Immutable tuple of sentence identifiers in processing order\n",
    "vocab          # Frozenset of unique words across all sentences\n",
    "tagset         # Frozenset of unique POS tags used in the corpus\n",
    "X              # Tuple of word sequences grouped by sentence\n",
    "Y              # Tuple of tag sequences grouped by sentence (parallel to X)\n",
    "N              # Total count of individual word tokens across all sentences\n",
    "```\n",
    "\n",
    "#### Common Methods\n",
    "```python\n",
    "stream()       # Iterator yielding flattened (word, tag) pairs across sentences\n",
    "__iter__()     # Iterator over (sentence_id, Sentence) pairs\n",
    "__len__()      # Number of sentences in the collection\n",
    "```\n",
    "\n",
    "### Data Structure Example\n",
    "\n",
    "Consider a subset containing these sentences:\n",
    "```python\n",
    "sentences = {\n",
    "    \"s0\": Sentence((\"See\", \"Spot\", \"run\"), (\"VERB\", \"NOUN\", \"VERB\")),\n",
    "    \"s1\": Sentence((\"Spot\", \"ran\"), (\"NOUN\", \"VERB\"))\n",
    "}\n",
    "```\n",
    "\n",
    "The resulting subset attributes would be:\n",
    "\n",
    "```python\n",
    "subset.keys     # (\"s0\", \"s1\") - ordered tuple, not set\n",
    "subset.vocab    # {\"See\", \"Spot\", \"run\", \"ran\"} - unordered frozenset\n",
    "subset.tagset   # {\"VERB\", \"NOUN\"} - unordered frozenset\n",
    "subset.X        # ((\"See\", \"Spot\", \"run\"), (\"Spot\", \"ran\")) - matches key order\n",
    "subset.Y        # ((\"VERB\", \"NOUN\", \"VERB\"), (\"NOUN\", \"VERB\")) - parallel to X\n",
    "subset.N        # 5 - total word tokens (3 + 2)\n",
    "len(subset)     # 2 - number of sentences\n",
    "```\n",
    "\n",
    "### Key Design Principles\n",
    "\n",
    "**Immutability**: Using frozenset and tuple types prevents accidental data modification during model training, ensuring reproducible results.\n",
    "\n",
    "**Parallel Structure**: The `X` and `Y` attributes maintain identical ordering, enabling direct indexing correspondence between word and tag sequences.\n",
    "\n",
    "**Efficient Access**: Pre-computed vocabulary and tag sets eliminate repeated scanning operations during feature extraction and model training phases.\n",
    "\n",
    "**Consistent Interface**: Both `Dataset` and `Subset` implement the same methods, allowing interchangeable usage in training and evaluation code.\n",
    "\n",
    "The interface design supports typical NLP workflows where you need access to both sentence-level structure (for sequence models) and flattened token streams (for vocabulary analysis and basic statistics).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:35:52.360710Z",
     "start_time": "2024-10-09T14:35:51.503909Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57340 sentences in the corpus.\n",
      "There are 45872 sentences in the training set.\n",
      "There are 11468 sentences in the testing set.\n"
     ]
    }
   ],
   "source": [
    "data = Dataset(\"tags-universal.txt\", \"data/brown-universal.txt\", train_test_split=0.8)\n",
    "\n",
    "print(\"There are {} sentences in the corpus.\".format(len(data)))\n",
    "print(\"There are {} sentences in the training set.\".format(len(data.training_set)))\n",
    "print(\"There are {} sentences in the testing set.\".format(len(data.testing_set)))\n",
    "\n",
    "assert len(data) == len(data.training_set) + len(data.testing_set), \\\n",
    "       \"The number of sentences in the training set + testing set should sum to the number of sentences in the corpus\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentences\n",
    "\n",
    "`Dataset.sentences` is a dictionary of all sentences in the training corpus, each keyed to a unique sentence identifier. Each `Sentence` is itself an object with two attributes: a tuple of the words in the sentence named `words` and a tuple of the tag corresponding to each word named `tags`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: b100-38532\n",
      "words:\n",
      "\t('Perhaps', 'it', 'was', 'right', ';', ';')\n",
      "tags:\n",
      "\t('ADV', 'PRON', 'VERB', 'ADJ', '.', '.')\n"
     ]
    }
   ],
   "source": [
    "key = 'b100-38532'\n",
    "\n",
    "print(\"Sentence: {}\".format(key))\n",
    "print(\"words:\\n\\t{!s}\".format(data.sentences[key].words))\n",
    "print(\"tags:\\n\\t{!s}\".format(data.sentences[key].tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "**Note:** The underlying iterable sequence is **unordered** over the sentences in the corpus; it is not guaranteed to return the sentences in a consistent order between calls. Use `Dataset.stream()`, `Dataset.keys`, `Dataset.X`, or `Dataset.Y` attributes if you need ordered access to the data.\n",
    "</div>\n",
    "\n",
    "#### Counting Unique Elements\n",
    "\n",
    "You can access the list of unique words (the dataset vocabulary) via `Dataset.vocab` and the unique list of tags via `Dataset.tagset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:36:27.713390Z",
     "start_time": "2024-10-09T14:36:27.706170Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 1161192 samples of 56057 unique words in the corpus.\n",
      "There are 928458 samples of 50536 unique words in the training set.\n",
      "There are 232734 samples of 25112 unique words in the testing set.\n",
      "There are 5521 words in the test set that are missing in the training set.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are a total of {} samples of {} unique words in the corpus.\"\n",
    "      .format(data.N, len(data.vocab)))\n",
    "print(\"There are {} samples of {} unique words in the training set.\"\n",
    "      .format(data.training_set.N, len(data.training_set.vocab)))\n",
    "print(\"There are {} samples of {} unique words in the testing set.\"\n",
    "      .format(data.testing_set.N, len(data.testing_set.vocab)))\n",
    "print(\"There are {} words in the test set that are missing in the training set.\"\n",
    "      .format(len(data.testing_set.vocab - data.training_set.vocab)))\n",
    "\n",
    "assert data.N == data.training_set.N + data.testing_set.N, \\\n",
    "       \"The number of training + test samples should sum to the total number of samples\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing word and tag Sequences\n",
    "The `Dataset.X` and `Dataset.Y` attributes provide access to ordered collections of matching word and tag sequences for each sentence in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:36:32.993503Z",
     "start_time": "2024-10-09T14:36:32.990483Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: ('Mr.', 'Podger', 'had', 'thanked', 'him', 'gravely', ',', 'and', 'now', 'he', 'made', 'use', 'of', 'the', 'advice', '.')\n",
      "\n",
      "Labels 1: ('NOUN', 'NOUN', 'VERB', 'VERB', 'PRON', 'ADV', '.', 'CONJ', 'ADV', 'PRON', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
      "\n",
      "Sentence 2: ('But', 'there', 'seemed', 'to', 'be', 'some', 'difference', 'of', 'opinion', 'as', 'to', 'how', 'far', 'the', 'board', 'should', 'go', ',', 'and', 'whose', 'advice', 'it', 'should', 'follow', '.')\n",
      "\n",
      "Labels 2: ('CONJ', 'PRT', 'VERB', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'ADP', 'ADV', 'ADV', 'DET', 'NOUN', 'VERB', 'VERB', '.', 'CONJ', 'DET', 'NOUN', 'PRON', 'VERB', 'VERB', '.')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accessing words with Dataset.X and tags with Dataset.Y \n",
    "for i in range(2):    \n",
    "    print(\"Sentence {}:\".format(i + 1), data.X[i])\n",
    "    print()\n",
    "    print(\"Labels {}:\".format(i + 1), data.Y[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing (word, tag) Samples\n",
    "The `Dataset.stream()` method returns an iterator that chains together every pair of (word, tag) entries across all sentences in the entire corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:36:37.477568Z",
     "start_time": "2024-10-09T14:36:37.474019Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stream (word, tag) pairs:\n",
      "\n",
      "\t ('Mr.', 'NOUN')\n",
      "\t ('Podger', 'NOUN')\n",
      "\t ('had', 'VERB')\n",
      "\t ('thanked', 'VERB')\n",
      "\t ('him', 'PRON')\n",
      "\t ('gravely', 'ADV')\n",
      "\t (',', '.')\n"
     ]
    }
   ],
   "source": [
    "# use Dataset.stream() (word, tag) samples for the entire corpus\n",
    "print(\"\\nStream (word, tag) pairs:\\n\")\n",
    "\n",
    "for i, pair in enumerate(data.stream()):\n",
    "    print(\"\\t\", pair)\n",
    "    if i > 5: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For both our baseline tagger and the HMM model we'll build, we need to estimate the frequency of tags & words from the frequency counts of observations in the training corpus. In the next several cells you will complete functions to compute the counts of several sets of counts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "##### Step 2: Build a Most Frequent Class tagger\n",
    "\n",
    "Perhaps the simplest tagger (and a good baseline for tagger performance) is to simply choose the tag most frequently assigned to each word. This \"most frequent class\" tagger inspects each observed word in the sequence and assigns it the label that was most often assigned to that word in the corpus.\n",
    "\n",
    "### IMPLEMENTATION: Pair Counts\n",
    "\n",
    "Complete the function below that computes the joint frequency counts for two input sequences.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:37:15.388249Z",
     "start_time": "2024-10-09T14:37:15.217698Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your emission counts look good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pair_counts(sequences_A, sequences_B):\n",
    "    \"\"\"Return a dictionary keyed to each unique value in the first sequence list\n",
    "    that counts the number of occurrences of the corresponding value from the\n",
    "    second sequences list.\n",
    "    \n",
    "    For example, if sequences_A is tags and sequences_B is the corresponding\n",
    "    words, then if 1244 sequences contain the word \"time\" tagged as a NOUN, then\n",
    "    you should return a dictionary such that pair_counts[NOUN][time] == 1244\n",
    "    \"\"\"\n",
    "    counts = defaultdict(lambda: defaultdict(int))\n",
    "    for seq_A, seq_B in zip(sequences_A, sequences_B):\n",
    "        for a, b in zip(seq_A, seq_B):\n",
    "            counts[a][b] += 1\n",
    "    return counts\n",
    "\n",
    "# Calculate C(t_i, w_i)\n",
    "emission_counts = pair_counts(data.training_set.Y, data.training_set.X)\n",
    "\n",
    "assert len(emission_counts) == 12, \\\n",
    "       \"Uh oh. There should be 12 tags in your dictionary.\"\n",
    "assert max(emission_counts[\"NOUN\"], key=emission_counts[\"NOUN\"].get) == 'time', \\\n",
    "       \"Hmmm...'time' is expected to be the most common NOUN.\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your emission counts look good!</div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPLEMENTATION: Most Frequent Class Tagger\n",
    "\n",
    "Use the `pair_counts()` function and the training dataset to find the most frequent class label for each word in the training data, and populate the `mfc_table` below. The table keys should be words, and the values should be the appropriate tag string.\n",
    "\n",
    "The `MFCTagger` class is provided to mock the interface of Pomegranite HMM models so that they can be used interchangeably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:38:08.775491Z",
     "start_time": "2024-10-09T14:38:08.484943Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your MFC tagger has all the correct words!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a lookup table mfc_table where mfc_table[word] contains the tag label most frequently assigned to that word\n",
    "from collections import namedtuple\n",
    "\n",
    "\"\"\"\n",
    "Lightweight state representation for compatibility with Pomegranate model interface.\n",
    "\n",
    "This namedtuple provides a minimal state object that mimics the structure of\n",
    "Pomegranate HMM states while avoiding the complexity of full model instantiation.\n",
    "Used primarily for interface compatibility in baseline models.\n",
    "\n",
    "Attributes:\n",
    "    name (str): Human-readable identifier for the state/tag\n",
    "\"\"\"\n",
    "FakeState = namedtuple(\"FakeState\", \"name\")\n",
    "\n",
    "class MFCTagger:\n",
    "    \"\"\"\n",
    "    Most Frequent Class baseline tagger for part-of-speech tagging evaluation.\n",
    "    \n",
    "    This baseline model assigns each word its most frequently observed POS tag\n",
    "    from the training data. For unseen words, it returns a special MISSING state.\n",
    "    The class provides a simplified interface compatible with more complex models\n",
    "    like HMMs for fair performance comparison.\n",
    "    \n",
    "    The MFC approach represents a strong baseline because:\n",
    "    - Many words have a dominant POS tag (e.g., \"the\" is almost always DET)\n",
    "    - It captures lexical preferences without considering context\n",
    "    - Performance degradation on unseen words highlights generalization challenges\n",
    "    \n",
    "    This baseline helps establish lower bounds for model performance and validates\n",
    "    that more complex approaches provide meaningful improvements over simple\n",
    "    frequency-based predictions.\n",
    "    \n",
    "    Attributes:\n",
    "        missing (FakeState): Default state returned for unknown words\n",
    "        table (defaultdict): Word-to-tag mapping with missing word fallback\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Class-level default state for handling out-of-vocabulary words.\n",
    "    Using a class attribute ensures consistent behavior across all instances\n",
    "    and provides a clear indicator for unseen word handling in predictions.\n",
    "    \"\"\"\n",
    "    missing = FakeState(name=\"<MISSING>\")\n",
    "    \n",
    "    def __init__(self, table: dict):\n",
    "        \"\"\"\n",
    "        Initialize MFC tagger with pre-computed word-to-tag frequency mappings.\n",
    "        \n",
    "        Creates a lookup table that returns the most frequent tag for known words\n",
    "        and a special MISSING state for unknown words. Uses defaultdict to handle\n",
    "        missing keys gracefully without raising KeyError exceptions.\n",
    "        \n",
    "        Args:\n",
    "            table (dict): Dictionary mapping words to their most frequent POS tags.\n",
    "                Keys are word strings, values are tag strings representing the\n",
    "                most commonly assigned tag for each word in training data.\n",
    "                \n",
    "        Example:\n",
    "            >>> mfc_table = {\"the\": \"DET\", \"cat\": \"NOUN\", \"runs\": \"VERB\"}\n",
    "            >>> tagger = MFCTagger(mfc_table)\n",
    "            >>> print(tagger.table[\"the\"].name)  # \"DET\"\n",
    "            >>> print(tagger.table[\"unknown\"].name)  # \"<MISSING>\"\n",
    "        \"\"\"\n",
    "        self.table = defaultdict(lambda: MFCTagger.missing)\n",
    "        self.table.update({word: FakeState(name=tag) for word, tag in table.items()})\n",
    "        \n",
    "    def viterbi(self, seq: list) -> tuple:\n",
    "        \"\"\"\n",
    "        Generate POS tag predictions for a word sequence using most frequent class assignment.\n",
    "        \n",
    "        This method provides interface compatibility with Pomegranate HMM models by\n",
    "        mimicking the viterbi() method signature and return format. However, instead\n",
    "        of performing dynamic programming inference, it simply assigns the most\n",
    "        frequent tag to each word independently.\n",
    "        \n",
    "        The method adds start and end tokens to match the expected format for\n",
    "        sequence models, enabling direct comparison with HMM performance without\n",
    "        interface modifications in evaluation code.\n",
    "        \n",
    "        Args:\n",
    "            seq (list): Sequence of word tokens to be tagged.\n",
    "                Should contain string tokens in the order they appear in the sentence.\n",
    "                \n",
    "        Returns:\n",
    "            tuple: Two-element tuple containing:\n",
    "                - float: Dummy log probability (always 0.0 for compatibility)\n",
    "                - list: Enumerated sequence of (index, state) pairs where each state\n",
    "                  is a FakeState object containing the predicted tag name. Includes\n",
    "                  special start and end states at positions 0 and -1.\n",
    "                  \n",
    "        Example:\n",
    "            >>> tagger = MFCTagger({\"cat\": \"NOUN\", \"runs\": \"VERB\"})\n",
    "            >>> prob, states = tagger.viterbi([\"cat\", \"runs\"])\n",
    "            >>> print(prob)  # 0.0\n",
    "            >>> print([state.name for _, state in states])\n",
    "            # [\"<start>\", \"NOUN\", \"VERB\", \"<end>\"]\n",
    "            \n",
    "        Note:\n",
    "            The enumerated output format matches Pomegranate's viterbi interface\n",
    "            where each element is (position, state). This enables seamless\n",
    "            integration with existing evaluation pipelines designed for HMM models.\n",
    "        \"\"\"\n",
    "        return 0., list(enumerate([\"<start>\"] + [self.table[w] for w in seq] + [\"<end>\"]))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Build most frequent class lookup table from training data word-tag co-occurrence statistics.\n",
    "\n",
    "This section computes the empirical frequency of each POS tag for every word in the\n",
    "training corpus, then selects the most frequent tag as the default prediction for\n",
    "each word. This approach captures the lexical preferences inherent in the language\n",
    "while ignoring contextual information.\n",
    "\n",
    "The frequency calculation process:\n",
    "1. Count all (word, tag) co-occurrences in training data\n",
    "2. For each word, identify the tag with maximum frequency\n",
    "3. Store word -> most_frequent_tag mappings in lookup table\n",
    "\n",
    "This baseline establishes performance expectations and validates that more complex\n",
    "models provide meaningful improvements over simple frequency-based predictions.\n",
    "\"\"\"\n",
    "\n",
    "# Calculate word-tag co-occurrence frequencies across the training corpus\n",
    "word_counts = pair_counts(data.training_set.X, data.training_set.Y)\n",
    "\n",
    "\"\"\"\n",
    "Create most frequent class lookup table by selecting the highest frequency tag for each word.\n",
    "\n",
    "For each word in the training vocabulary, this loop identifies the POS tag that\n",
    "appeared most frequently with that word and stores the mapping in mfc_table.\n",
    "This represents the optimal prediction for each word under the assumption that\n",
    "context doesn't matter and lexical frequency is the primary signal.\n",
    "\n",
    "The max() function with key=tag_counts.get efficiently finds the tag with the\n",
    "highest count for each word, handling ties deterministically based on the\n",
    "internal ordering of the tag_counts dictionary.\n",
    "\"\"\"\n",
    "mfc_table = {}\n",
    "for word, tag_counts in word_counts.items():\n",
    "    mfc_table[word] = max(tag_counts, key=tag_counts.get)\n",
    "\n",
    "# DO NOT MODIFY BELOW THIS LINE\n",
    "\"\"\"\n",
    "Instantiate the MFC baseline tagger with computed frequency table.\n",
    "\n",
    "This creates the baseline model that will be compared against more sophisticated\n",
    "approaches like Hidden Markov Models. The MFC tagger provides a strong but\n",
    "simple baseline that captures lexical preferences without contextual reasoning.\n",
    "\"\"\"\n",
    "mfc_model = MFCTagger(mfc_table)\n",
    "\n",
    "\"\"\"\n",
    "Validation assertions to ensure correct MFC table construction.\n",
    "\n",
    "These checks verify:\n",
    "1. MFC table covers all words in training vocabulary (no missing entries)\n",
    "2. All MFC table keys correspond to actual training vocabulary words\n",
    "3. Expected number of out-of-vocabulary words in testing set (5521)\n",
    "\n",
    "The assertions confirm that the baseline model is properly constructed and\n",
    "that the train-test split has the expected vocabulary overlap characteristics.\n",
    "\"\"\"\n",
    "assert len(mfc_table) == len(data.training_set.vocab), \"MFC table size must match training vocabulary\"\n",
    "assert all(k in data.training_set.vocab for k in mfc_table.keys()), \"All MFC keys must be in training vocab\"\n",
    "assert sum(int(k not in mfc_table) for k in data.testing_set.vocab) == 5521, \"Expected 5521 OOV words in test set\"\n",
    "\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your MFC tagger has all the correct words!</div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions with a Model\n",
    "The helper functions provided below interface with Pomegranate network models & the mocked MFCTagger to take advantage of the [missing value](http://pomegranate.readthedocs.io/en/latest/nan.html) functionality in Pomegranate through a simple sequence decoding function. Run these functions, then run the next cell to see some of the predictions made by the MFC tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:38:20.732915Z",
     "start_time": "2024-10-09T14:38:20.727842Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_unknown(sequence):\n",
    "    \"\"\"Return a copy of the input sequence where each unknown word is replaced\n",
    "    by the literal string value 'nan'. Pomegranate will ignore these values\n",
    "    during computation.\n",
    "    \"\"\"\n",
    "    return [w if w in data.training_set.vocab else 'nan' for w in sequence]\n",
    "\n",
    "def simplify_decoding(X, model):\n",
    "    \"\"\"X should be a 1-D sequence of observations for the model to predict\"\"\"\n",
    "    _, state_path = model.viterbi(replace_unknown(X))\n",
    "    return [state[1].name for state in state_path[1:-1]]  # do not show the start/end state predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Decoding Sequences with MFC Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:38:25.309005Z",
     "start_time": "2024-10-09T14:38:25.305126Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Key: b100-28144\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-23146\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-35462\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', '<MISSING>', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADV', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in data.testing_set.keys[:3]:\n",
    "    print(\"Sentence Key: {}\\n\".format(key))\n",
    "    print(\"Predicted labels:\\n-----------------\")\n",
    "    print(simplify_decoding(data.sentences[key].words, mfc_model))\n",
    "    print()\n",
    "    print(\"Actual labels:\\n--------------\")\n",
    "    print(data.sentences[key].tags)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model Accuracy\n",
    "\n",
    "The function below will evaluate the accuracy of the MFC tagger on the collection of all sentences from a text corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:39:49.460904Z",
     "start_time": "2024-10-09T14:39:49.454775Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(X, Y, model):\n",
    "    \"\"\"Calculate the prediction accuracy by using the model to decode each sequence\n",
    "    in the input X and comparing the prediction with the true labels in Y.\n",
    "    \n",
    "    The X should be an array whose first dimension is the number of sentences to test,\n",
    "    and each element of the array should be an iterable of the words in the sequence.\n",
    "    The arrays X and Y should have the exact same shape.\n",
    "    \n",
    "    X = [(\"See\", \"Spot\", \"run\"), (\"Run\", \"Spot\", \"run\", \"fast\"), ...]\n",
    "    Y = [(), (), ...]\n",
    "    \"\"\"\n",
    "    correct = total_predictions = 0\n",
    "    for observations, actual_tags in zip(X, Y):\n",
    "        \n",
    "        # The model.viterbi call in simplify_decoding will return None if the HMM\n",
    "        # raises an error (for example, if a test sentence contains a word that\n",
    "        # is out of vocabulary for the training set). Any exception counts the\n",
    "        # full sentence as an error (which makes this a conservative estimate).\n",
    "        try:\n",
    "            most_likely_tags = simplify_decoding(observations, model)\n",
    "            correct += sum(p == t for p, t in zip(most_likely_tags, actual_tags))\n",
    "        except:\n",
    "            pass\n",
    "        total_predictions += len(observations)\n",
    "    return correct / total_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the accuracy of the MFC tagger\n",
    "Run the next cell to evaluate the accuracy of the tagger on the training and test corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:40:12.339033Z",
     "start_time": "2024-10-09T14:40:11.928661Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy mfc_model: 95.72%\n",
      "testing accuracy mfc_model: 93.01%\n"
     ]
    }
   ],
   "source": [
    "mfc_training_acc = accuracy(data.training_set.X, data.training_set.Y, mfc_model)\n",
    "print(\"training accuracy mfc_model: {:.2f}%\".format(100 * mfc_training_acc))\n",
    "\n",
    "mfc_testing_acc = accuracy(data.testing_set.X, data.testing_set.Y, mfc_model)\n",
    "print(\"testing accuracy mfc_model: {:.2f}%\".format(100 * mfc_testing_acc))\n",
    "\n",
    "assert mfc_training_acc >= 0.955, \"Uh oh. Your MFC accuracy on the training set doesn't look right.\"\n",
    "assert mfc_testing_acc >= 0.925, \"Uh oh. Your MFC accuracy on the testing set doesn't look right.\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your MFC tagger accuracy looks correct!</div>')\n",
    "\n",
    "def unigram_counts(sequences):\n",
    "    \"\"\"Return a dictionary keyed to each unique value in the input sequence list that\n",
    "    counts the number of occurrences of the value in the sequences list. The sequences\n",
    "    collection should be a 2-dimensional array.\n",
    "    \n",
    "    For example, if the tag NOUN appears 275558 times over all the input sequences,\n",
    "    then you should return a dictionary such that your_unigram_counts[NOUN] == 275558.\n",
    "    \"\"\"\n",
    "    counts = defaultdict(int)\n",
    "    for sequence in sequences:\n",
    "        for item in sequence:\n",
    "            counts[item] += 1\n",
    "    return counts\n",
    "\n",
    "# Call unigram_counts with a list of tag sequences from the training set\n",
    "tag_unigrams = unigram_counts(data.training_set.Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "##### Step 3: Build an HMM tagger\n",
    "\n",
    "The HMM tagger has one hidden state for each possible tag, and parameterized by two distributions: the emission probabilties giving the conditional probability of observing a given **word** from each hidden state, and the transition probabilities giving the conditional probability of moving between **tags** during the sequence.\n",
    "\n",
    "We will also estimate the starting probability distribution (the probability of each **tag** being the first tag in a sequence), and the terminal probability distribution (the probability of each **tag** being the last tag in a sequence).\n",
    "\n",
    "The maximum likelihood estimate of these distributions can be calculated from the frequency counts as described in the following sections where you'll implement functions to count the frequencies, and finally build the model. The HMM model will make predictions according to the formula:\n",
    "\n",
    "$$t_i^n = \\underset{t_i^n}{\\mathrm{argmax}} \\prod_{i=1}^n P(w_i|t_i) P(t_i|t_{i-1})$$\n",
    "\n",
    "Refer to Speech & Language Processing [Chapter 10](https://web.stanford.edu/~jurafsky/slp3/10.pdf) for more information.\n",
    "\n",
    "### IMPLEMENTATION: Unigram Counts\n",
    "\n",
    "Complete the function below to estimate the co-occurrence frequency of each symbol over all of the input sequences. The unigram probabilities in our HMM model are estimated from the formula below, where N is the total number of samples in the input. (You only need to compute the counts for now.)\n",
    "\n",
    "$$P(tag_1) = \\frac{C(tag_1)}{N}$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:40:17.281741Z",
     "start_time": "2024-10-09T14:40:17.277068Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your tag unigrams look good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "assert set(tag_unigrams.keys()) == data.training_set.tagset, \\\n",
    "       \"Uh oh. It looks like your tag counts doesn't include all the tags!\"\n",
    "assert min(tag_unigrams, key=tag_unigrams.get) == 'X', \\\n",
    "       \"Hmmm...'X' is expected to be the least common class\"\n",
    "assert max(tag_unigrams, key=tag_unigrams.get) == 'NOUN', \\\n",
    "       \"Hmmm...'NOUN' is expected to be the most common class\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your tag unigrams look good!</div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Bigram \n",
    "\n",
    "A **bigram** is a sequence of two adjacent elements in natural language processing and computational linguistics. In the context we've been discussing (POS tagging), bigrams refer to consecutive pairs of parts-of-speech tags or words.\n",
    "\n",
    "###### Types of Bigrams\n",
    "\n",
    "**Tag Bigrams**: Consecutive POS tag pairs\n",
    "- Example: (\"NOUN\", \"VERB\") from \"cat runs\"\n",
    "- Used for modeling grammatical transitions\n",
    "\n",
    "**Word Bigrams**: Consecutive word pairs  \n",
    "- Example: (\"New\", \"York\") or (\"ice\", \"cream\")\n",
    "- Used for language modeling and phrase detection\n",
    "\n",
    "###### Applications in NLP\n",
    "\n",
    "**Hidden Markov Models**: Bigram counts estimate transition probabilities between states (POS tags):\n",
    "$$P(\\text{tag}_j | \\text{tag}_i) = \\frac{\\text{count}(\\text{tag}_i, \\text{tag}_j)}{\\text{count}(\\text{tag}_i)}$$\n",
    "\n",
    "**Language Modeling**: Bigrams help predict the next word based on the previous word:\n",
    "$$P(\\text{word}_j | \\text{word}_i)$$\n",
    "\n",
    "**Pattern Recognition**: Identify common linguistic constructions and collocations in text.\n",
    "\n",
    "###### Example from Our Code Context\n",
    "\n",
    "In the `bigram_counts` function we just documented, if you have tag sequences:\n",
    "- `[\"DET\", \"NOUN\", \"VERB\"]`\n",
    "- `[\"NOUN\", \"VERB\", \"ADJ\"]`\n",
    "\n",
    "The bigrams would be:\n",
    "- (\"DET\", \"NOUN\"): count = 1\n",
    "- (\"NOUN\", \"VERB\"): count = 2  \n",
    "- (\"VERB\", \"ADJ\"): count = 1\n",
    "\n",
    "These counts are essential for training HMM models where you need to learn how likely one POS tag is to follow another in natural language.\n",
    "\n",
    "Complete the function below to estimate the co-occurrence frequency of each pair of symbols in each of the input sequences. These counts are used in the HMM model to estimate the bigram probability of two tags from the frequency counts according to the formula: $$P(tag_2|tag_1) = \\frac{C(tag_2|tag_1)}{C(tag_2)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:40:35.463408Z",
     "start_time": "2024-10-09T14:40:35.304881Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your tag bigrams look good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bigram_counts(sequences):\n",
    "    \"\"\"\n",
    "    Calculate frequency counts for consecutive element pairs across multiple sequences.\n",
    "    \n",
    "    This function computes bigram statistics by counting all adjacent pairs of elements\n",
    "    that appear in the input sequences. Bigrams are fundamental in natural language\n",
    "    processing for modeling sequential dependencies, particularly useful for:\n",
    "    - POS tag transition probabilities in Hidden Markov Models\n",
    "    - Word co-occurrence patterns in language modeling\n",
    "    - Sequential pattern analysis in any ordered data\n",
    "    \n",
    "    The function processes each sequence independently and accumulates counts across\n",
    "    all sequences, providing corpus-level bigram statistics essential for probabilistic\n",
    "    sequence models.\n",
    "    \n",
    "    Args:\n",
    "        sequences (list): 2-dimensional array where each inner sequence contains\n",
    "            ordered elements (strings, tags, tokens, etc.). Each sequence represents\n",
    "            an independent ordered collection (e.g., sentences with POS tags).\n",
    "            Example: [[\"NOUN\", \"VERB\", \"ADJ\"], [\"DET\", \"NOUN\", \"VERB\"]]\n",
    "            \n",
    "    Returns:\n",
    "        dict: Dictionary mapping bigram tuples to their occurrence counts.\n",
    "            Keys are (element1, element2) tuples representing consecutive pairs.\n",
    "            Values are integers representing frequency counts across all sequences.\n",
    "            Uses defaultdict(int) for efficient counting without key existence checks.\n",
    "            \n",
    "    Example:\n",
    "        >>> tag_sequences = [\n",
    "        ...     [\"NOUN\", \"VERB\", \"ADJ\"],\n",
    "        ...     [\"NOUN\", \"VERB\", \"NOUN\"],\n",
    "        ...     [\"DET\", \"NOUN\", \"VERB\"]\n",
    "        ... ]\n",
    "        >>> counts = bigram_counts(tag_sequences)\n",
    "        >>> print(counts[(\"NOUN\", \"VERB\")])  # 3 (appears in all sequences)\n",
    "        >>> print(counts[(\"VERB\", \"ADJ\")])   # 1 (appears once)\n",
    "        >>> print(counts[(\"DET\", \"NOUN\")])   # 1 (appears once)\n",
    "        \n",
    "    Mathematical Foundation:\n",
    "        For HMM training, bigram counts enable transition probability estimation:\n",
    "        P(tag_j | tag_i) = count(tag_i, tag_j) / count(tag_i)\n",
    "        \n",
    "        Where bigram_counts provides the numerator count(tag_i, tag_j).\n",
    "        \n",
    "    Implementation Details:\n",
    "        - Uses sliding window approach with range(len(sequence) - 1)\n",
    "        - Handles sequences of any length, including single elements (no bigrams)\n",
    "        - Empty sequences contribute no counts (graceful handling)\n",
    "        - Memory efficient: O(unique_bigrams) space complexity\n",
    "        \n",
    "    Performance Considerations:\n",
    "        - Time complexity: O(total_sequence_length) across all sequences\n",
    "        - Space complexity: O(unique_bigrams) for the resulting dictionary\n",
    "        - Uses defaultdict(int) to avoid repeated key existence checks\n",
    "        \n",
    "    Note:\n",
    "        This function does not add special start/end tokens. For HMM applications\n",
    "        requiring sentence boundary modeling, preprocess sequences to include\n",
    "        \"<start>\" and \"<end>\" tokens before calling this function.\n",
    "    \"\"\"\n",
    "    counts = defaultdict(int)\n",
    "    for sequence in sequences:\n",
    "        for i in range(len(sequence) - 1):\n",
    "            counts[(sequence[i], sequence[i+1])] += 1\n",
    "    return counts\n",
    "    \n",
    "\n",
    "# Call bigram_counts with a list of tag sequences from the training set\n",
    "tag_bigrams = bigram_counts(data.training_set.Y)\n",
    "\n",
    "assert len(tag_bigrams) == 144, \\\n",
    "       \"Uh oh. There should be 144 pairs of bigrams (12 tags x 12 tags)\"\n",
    "assert min(tag_bigrams, key=tag_bigrams.get) in [('X', 'NUM'), ('PRON', 'X')], \\\n",
    "       \"Hmmm...The least common bigram should be one of ('X', 'NUM') or ('PRON', 'X').\"\n",
    "assert max(tag_bigrams, key=tag_bigrams.get) in [('DET', 'NOUN')], \\\n",
    "       \"Hmmm...('DET', 'NOUN') is expected to be the most common bigram.\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your tag bigrams look good!</div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPLEMENTATION: Sequence Starting Counts\n",
    "Complete the code below to estimate the bigram probabilities of a sequence starting with each tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:40:53.542787Z",
     "start_time": "2024-10-09T14:40:53.524698Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your starting tag counts look good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def starting_counts(sequences):\n",
    "    \"\"\"Return a dictionary keyed to each unique value in the input sequences list\n",
    "    that counts the number of occurrences where that value is at the beginning of\n",
    "    a sequence.\n",
    "    \n",
    "    For example, if 8093 sequences start with NOUN, then you should return a\n",
    "    dictionary such that your_starting_counts[NOUN] == 8093\n",
    "    \"\"\"\n",
    "    counts = defaultdict(int)\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        if sequence:\n",
    "            counts[sequence[0]] += 1\n",
    "    return counts\n",
    "\n",
    "# Calculate the count of each tag starting a sequence\n",
    "tag_starts = starting_counts(data.training_set.Y)\n",
    "\n",
    "assert len(tag_starts) == 12, \"Uh oh. There should be 12 tags in your dictionary.\"\n",
    "assert min(tag_starts, key=tag_starts.get) == 'X', \"Hmmm...'X' is expected to be the least common starting bigram.\"\n",
    "assert max(tag_starts, key=tag_starts.get) == 'DET', \"Hmmm...'DET' is expected to be the most common starting bigram.\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your starting tag counts look good!</div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPLEMENTATION: Sequence Ending Counts\n",
    "Complete the function below to estimate the bigram probabilities of a sequence ending with each tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:41:21.427830Z",
     "start_time": "2024-10-09T14:41:21.411680Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your ending tag counts look good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ending_counts(sequences):\n",
    "    \"\"\"Return a dictionary keyed to each unique value in the input sequences list\n",
    "    that counts the number of occurrences where that value is at the end of\n",
    "    a sequence.\n",
    "    \n",
    "    For example, if 18 sequences end with DET, then you should return a\n",
    "    dictionary such that your_starting_counts[DET] == 18\n",
    "    \"\"\"\n",
    "    counts = defaultdict(int)\n",
    "    for sequence in sequences:\n",
    "        if sequence:\n",
    "            counts[sequence[-1]] += 1\n",
    "    return counts\n",
    "\n",
    "# Calculate the count of each tag ending a sequence\n",
    "tag_ends = ending_counts(data.training_set.Y)\n",
    "\n",
    "assert len(tag_ends) == 12, \"Uh oh. There should be 12 tags in your dictionary.\"\n",
    "assert min(tag_ends, key=tag_ends.get) in ['X', 'CONJ'], \"Hmmm...'X' or 'CONJ' should be the least common ending bigram.\"\n",
    "assert max(tag_ends, key=tag_ends.get) == '.', \"Hmmm...'.' is expected to be the most common ending bigram.\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your ending tag counts look good!</div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPLEMENTATION: Basic HMM Tagger\n",
    "Use the tag unigrams and bigrams calculated above to construct a hidden Markov tagger.\n",
    "\n",
    "- Add one state per tag\n",
    "    - The emission distribution at each state should be estimated with the formula: $P(w|t) = \\frac{C(t, w)}{C(t)}$\n",
    "- Add an edge from the starting state `basic_model.start` to each tag\n",
    "    - The transition probability should be estimated with the formula: $P(t|start) = \\frac{C(start, t)}{C(start)}$\n",
    "- Add an edge from each tag to the end state `basic_model.end`\n",
    "    - The transition probability should be estimated with the formula: $P(end|t) = \\frac{C(t, end)}{C(t)}$\n",
    "- Add an edge between _every_ pair of tags\n",
    "    - The transition probability should be estimated with the formula: $P(t_2|t_1) = \\frac{C(t_1, t_2)}{C(t_1)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:46:21.119713Z",
     "start_time": "2024-10-09T14:46:21.012834Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your HMM network topology looks good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_model = HiddenMarkovModel(name=\"base-hmm-tagger\")\n",
    "\n",
    "# Create states with emission probability distributions P(word | tag) and add to the model\n",
    "states = {}\n",
    "for tag in data.training_set.tagset:\n",
    "    emissions = {word: emission_counts[tag][word] / tag_unigrams[tag] for word in emission_counts[tag]}\n",
    "    state = State(DiscreteDistribution(emissions), name=tag)\n",
    "    states[tag] = state\n",
    "    basic_model.add_state(state)\n",
    "\n",
    "# Add edges between states for the observed transition frequencies P(tag_i | tag_i-1)\n",
    "for tag1 in data.training_set.tagset:\n",
    "    # Add start transitions\n",
    "    basic_model.add_transition(basic_model.start, states[tag1], tag_starts[tag1] / len(data.training_set))\n",
    "    \n",
    "    # Add end transitions\n",
    "    basic_model.add_transition(states[tag1], basic_model.end, tag_ends[tag1] / tag_unigrams[tag1])\n",
    "    \n",
    "    # Add transitions between tags\n",
    "    for tag2 in data.training_set.tagset:\n",
    "        basic_model.add_transition(\n",
    "            states[tag1],\n",
    "            states[tag2],\n",
    "            tag_bigrams[(tag1, tag2)] / tag_unigrams[tag1]\n",
    "        )\n",
    "\n",
    "# finalize the model\n",
    "basic_model.bake()\n",
    "\n",
    "assert all(tag in set(s.name for s in basic_model.states) for tag in data.training_set.tagset), \\\n",
    "       \"Every state in your network should use the name of the associated tag, which must be one of the training set tags.\"\n",
    "assert basic_model.edge_count() == 168, \\\n",
    "       (\"Your network should have an edge from the start node to each state, one edge between every \" +\n",
    "        \"pair of tags (states), and an edge from each state to the end node.\")\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your HMM network topology looks good!</div>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:46:26.254430Z",
     "start_time": "2024-10-09T14:46:25.189425Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy basic hmm model: 97.54%\n",
      "testing accuracy basic hmm model: 95.95%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your HMM tagger accuracy looks correct! Congratulations, you've finished the project.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_training_acc = accuracy(data.training_set.X, data.training_set.Y, basic_model)\n",
    "print(\"training accuracy basic hmm model: {:.2f}%\".format(100 * hmm_training_acc))\n",
    "\n",
    "hmm_testing_acc = accuracy(data.testing_set.X, data.testing_set.Y, basic_model)\n",
    "print(\"testing accuracy basic hmm model: {:.2f}%\".format(100 * hmm_testing_acc))\n",
    "\n",
    "assert hmm_training_acc > 0.97, \"Uh oh. Your HMM accuracy on the training set doesn't look right.\"\n",
    "assert hmm_training_acc > 0.955, \"Uh oh. Your HMM accuracy on the training set doesn't look right.\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your HMM tagger accuracy looks correct! Congratulations, you\\'ve finished the project.</div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Decoding Sequences with the HMM Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:46:32.939352Z",
     "start_time": "2024-10-09T14:46:32.935119Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Key: b100-28144\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-23146\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-35462\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in data.testing_set.keys[:3]:\n",
    "    print(\"Sentence Key: {}\\n\".format(key))\n",
    "    print(\"Predicted labels:\\n-----------------\")\n",
    "    print(simplify_decoding(data.sentences[key].words, basic_model))\n",
    "    print()\n",
    "    print(\"Actual labels:\\n--------------\")\n",
    "    print(data.sentences[key].tags)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Finishing the project\n",
    "---\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "**Note:** **SAVE YOUR NOTEBOOK**, then run the next cell to generate an HTML copy. You will zip & submit both this file and the HTML copy for review.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T14:52:23.853170Z",
     "start_time": "2024-10-09T14:52:22.489025Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[NbConvertApp] Converting notebook hmm_tagger.ipynb to html',\n",
       " '[NbConvertApp] Writing 382865 bytes to hmm_tagger.html',\n",
       " '[NbConvertApp] Converting notebook hmm_warmup.ipynb to html',\n",
       " '[NbConvertApp] WARNING | Alternative text is missing on 1 image(s).',\n",
       " '[NbConvertApp] Writing 334346 bytes to hmm_warmup.html']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!jupyter nbconvert --to html *.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: [Optional] Improving model performance\n",
    "---\n",
    "There are additional enhancements that can be incorporated into your tagger that improve performance on larger tagsets where the data sparsity problem is more significant. The data sparsity problem arises because the same amount of data split over more tags means there will be fewer samples in each tag, and there will be more missing data  tags that have zero occurrences in the data. The techniques in this section are optional.\n",
    "\n",
    "- [Laplace Smoothing](https://en.wikipedia.org/wiki/Additive_smoothing) (pseudocounts)\n",
    "    Laplace smoothing is a technique where you add a small, non-zero value to all observed counts to offset for unobserved values.\n",
    "\n",
    "- Backoff Smoothing\n",
    "    Another smoothing technique is to interpolate between n-grams for missing data. This method is more effective than Laplace smoothing at combatting the data sparsity problem. Refer to chapters 4, 9, and 10 of the [Speech & Language Processing](https://web.stanford.edu/~jurafsky/slp3/) book for more information.\n",
    "\n",
    "- Extending to Trigrams\n",
    "    HMM taggers have achieved better than 96% accuracy on this dataset with the full Penn treebank tagset using an architecture described in [this](http://www.coli.uni-saarland.de/~thorsten/publications/Brants-ANLP00.pdf) paper. Altering your HMM to achieve the same performance would require implementing deleted interpolation (described in the paper), incorporating trigram probabilities in your frequency tables, and re-implementing the Viterbi algorithm to consider three consecutive states instead of two.\n",
    "\n",
    "### Obtain the Brown Corpus with a Larger Tagset\n",
    "Run the code below to download a copy of the brown corpus with the full NLTK tagset. You will need to research the available tagset information in the NLTK docs and determine the best way to extract the subset of NLTK tags you want to explore. If you write the following the format specified in Step 1, then you can reload the data using all of the code above for comparison.\n",
    "\n",
    "Refer to [Chapter 5](http://www.nltk.org/book/ch05.html) of the NLTK book for more information on the available tagsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import brown\n",
    "\n",
    "nltk.download('brown')\n",
    "training_corpus = nltk.corpus.brown\n",
    "training_corpus.tagged_sents()[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
